{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract patent information from Google Patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [\"https://patents.google.com/patent/US9858496B2/en\"]\n",
    "# seed prior art\n",
    "# Faster R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "TWO_BYTE = re.compile(r'[^\\x01-\\x7E]')\n",
    "\n",
    "def remove_two_byte(text):\n",
    "  return TWO_BYTE.sub('', text)\n",
    "\n",
    "def get_results(soup):\n",
    "  result_1 = defaultdict(str)\n",
    "  result_2 = defaultdict(list)\n",
    "  result_3 = defaultdict(list)\n",
    "\n",
    "  # for elm in soup.find_all('div'):\n",
    "  #   if elm.get('itemprop') == 'content':\n",
    "  #     if elm.contents[0].name == 'abstract':\n",
    "  #       result_1[elm.contents[0].name] = remove_two_byte(elm.get_text(separator=\" \", strip=True)).replace(\"\\n\",\" \")\n",
    "  #     else:\n",
    "  #       result_1[elm.contents[0]['class'][0]] = remove_two_byte(elm.get_text(separator=\" \", strip=True)).replace(\"\\n\",\" \")\n",
    "\n",
    "  tmp = soup.find('section', attrs={'itemprop':'abstract'})\n",
    "  if tmp:\n",
    "    result_1[\"abstract\"] = remove_two_byte(tmp.get_text(separator=\" \", strip=True)).replace(\"\\n\",\" \")\n",
    "\n",
    "  tmp = soup.find('section', attrs={'itemprop':'claims'})\n",
    "  if tmp:\n",
    "    result_1[\"claims\"] = remove_two_byte(tmp.get_text(separator=\" \", strip=True)).replace(\"\\n\",\" \")\n",
    "  \n",
    "  tmp = soup.find('section', attrs={'itemprop':'description'})\n",
    "  if tmp:\n",
    "    result_1[\"description\"]  = remove_two_byte(tmp.get_text(separator=\" \", strip=True)).replace(\"\\n\",\" \")\n",
    "\n",
    "  tmp = soup.find('span', attrs={'itemprop':'assigneeSearch'})\n",
    "  if tmp:\n",
    "    result_1[\"assignee\"]  = tmp.get_text(separator=\" \", strip=True)\n",
    "  \n",
    "  tmp = soup.find('time', attrs={'itemprop':'priorityDate'})\n",
    "  if tmp:\n",
    "    result_1[\"priority_date\"]  = tmp.get_text(separator=\" \", strip=True)\n",
    "\n",
    "  for elm in soup.find_all(\"span\", attrs = {\"itemprop\":\"examinerCited\"}):\n",
    "    if elm.find_parent(\"tr\").get(\"itemprop\") == \"forwardReferencesOrig\" or elm.find_parent(\"tr\").get(\"itemprop\") == \"forwardReferencesFamily\":\n",
    "      result_2[\"ForwardReferences\"] += [\"https://patents.google.com\" + elm.find_previous_sibling(\"a\").get(\"href\")]\n",
    "    if elm.find_parent(\"tr\").get(\"itemprop\") == \"backwardReferencesOrig\" or elm.find_parent(\"tr\").get(\"itemprop\") == \"backwardReferencesFamily\":\n",
    "      result_2[\"BackwardReferences\"] += [\"https://patents.google.com\" + elm.find_previous_sibling(\"a\").get(\"href\")]\n",
    "  \n",
    "  for elm in soup.find_all('meta', attrs={'itemprop':'Leaf'}):\n",
    "    result_3[\"cpc\"] += [elm.find_previous_sibling(\"span\", attrs={'itemprop':'Code'}).get_text(strip=True)]\n",
    "    result_3[\"description\"] += [elm.find_previous_sibling(\"span\", attrs={'itemprop':'Description'}).get_text(strip=True)]\n",
    "    \n",
    "  return result_1, result_2, result_3\n",
    "\n",
    "def get_text_dict(url):\n",
    "  res = requests.get(url)\n",
    "  res.encoding = res.apparent_encoding\n",
    "  soup = BeautifulSoup(res.text, 'html.parser')\n",
    "  result_1, result_2, result_3 = get_results(soup)\n",
    "  if result_1[\"abstract\"] == \"\":\n",
    "    print(\"abstract none\")\n",
    "    result_1[\"abstract\"] = \"abstract\"\n",
    "\n",
    "  if result_1[\"claims\"] == \"\":\n",
    "    print(\"claims none\")\n",
    "    result_1[\"claims\"] = \"claims\"\n",
    "\n",
    "  if result_1[\"description\"] == \"\":\n",
    "    print(\"description none\")\n",
    "    result_1[\"description\"] = \"description\"\n",
    "\n",
    "  if result_1[\"assignee\"] == \"\":\n",
    "    print(\"assignee none\")\n",
    "    result_1[\"assignee\"] = \"unkown\"\n",
    "\n",
    "  if result_1[\"priority_date\"] == \"\":\n",
    "    print(\"priority_date none\")\n",
    "    result_1[\"priority_date\"] = \"\"\n",
    "\n",
    "  return result_1, result_2, result_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-1 : https://patents.google.com/patent/US9858496B2/en\n",
      "Total 1 data.\n",
      "Loop 2. 42 data will be extracted.\n",
      "2-1 : https://patents.google.com/patent/US20180107866A1/en\n",
      "2-2 : https://patents.google.com/patent/CN108520229A/en\n",
      "2-3 : https://patents.google.com/patent/CN108573228A/en\n",
      "2-4 : https://patents.google.com/patent/US10242294B2/en\n",
      "2-5 : https://patents.google.com/patent/US10304009B1/en\n",
      "2-6 : https://patents.google.com/patent/US10366430B2/en\n",
      "2-7 : https://patents.google.com/patent/WO2019148729A1/en\n",
      "2-8 : https://patents.google.com/patent/US10380741B2/en\n",
      "2-9 : https://patents.google.com/patent/US10262237B2/en\n",
      "2-10 : https://patents.google.com/patent/US20180260415A1/en\n",
      "2-11 : https://patents.google.com/patent/US10255525B1/en\n",
      "2-12 : https://patents.google.com/patent/US10303956B2/en\n",
      "2-13 : https://patents.google.com/patent/CN107562925A/en\n",
      "2-14 : https://patents.google.com/patent/WO2019068141A1/en\n",
      "2-15 : https://patents.google.com/patent/US10169679B1/en\n",
      "2-16 : https://patents.google.com/patent/US10007865B1/en\n",
      "2-17 : https://patents.google.com/patent/US10467501B2/en\n",
      "2-18 : https://patents.google.com/patent/WO2019136479A1/en\n",
      "2-19 : https://patents.google.com/patent/WO2019220622A1/en\n",
      "2-20 : https://patents.google.com/patent/US10579924B1/en\n",
      "2-21 : https://patents.google.com/patent/US10303981B1/en\n",
      "2-22 : https://patents.google.com/patent/US10438082B1/en\n",
      "2-23 : https://patents.google.com/patent/US10346693B1/en\n",
      "2-24 : https://patents.google.com/patent/US10402692B1/en\n",
      "2-25 : https://patents.google.com/patent/US10509987B1/en\n",
      "2-26 : https://patents.google.com/patent/US10395140B1/en\n",
      "2-27 : https://patents.google.com/patent/US10325185B1/en\n",
      "2-28 : https://patents.google.com/patent/US10325352B1/en\n",
      "2-29 : https://patents.google.com/patent/US10387753B1/en\n",
      "2-30 : https://patents.google.com/patent/US10410120B1/en\n",
      "2-31 : https://patents.google.com/patent/US10452980B1/en\n",
      "2-32 : https://patents.google.com/patent/US10496899B1/en\n",
      "2-33 : https://patents.google.com/patent/US10445611B1/en\n",
      "2-34 : https://patents.google.com/patent/US10373323B1/en\n",
      "2-35 : https://patents.google.com/patent/US10373027B1/en\n",
      "2-36 : https://patents.google.com/patent/US7890443B2/en\n",
      "2-37 : https://patents.google.com/patent/US8010471B2/en\n",
      "2-38 : https://patents.google.com/patent/US20110311129A1/en\n",
      "2-39 : https://patents.google.com/patent/US20120207346A1/en\n",
      "2-40 : https://patents.google.com/patent/US20140270551A1/en\n",
      "2-41 : https://patents.google.com/patent/US9147255B1/en\n",
      "2-42 : https://patents.google.com/patent/US9418319B2/en\n",
      "Total 43 data.\n",
      "Loop 3. 669 data will be extracted.\n",
      "3-1 : https://patents.google.com/patent/CN108520229A/en\n",
      "3-2 : https://patents.google.com/patent/US10242294B2/en\n",
      "3-3 : https://patents.google.com/patent/US10366430B2/en\n",
      "3-4 : https://patents.google.com/patent/US10380741B2/en\n",
      "3-5 : https://patents.google.com/patent/US20180260415A1/en\n",
      "3-6 : https://patents.google.com/patent/US10303956B2/en\n",
      "3-7 : https://patents.google.com/patent/WO2019068141A1/en\n",
      "3-8 : https://patents.google.com/patent/WO2019136479A1/en\n",
      "3-9 : https://patents.google.com/patent/US10579924B1/en\n",
      "3-10 : https://patents.google.com/patent/US10325352B1/en\n",
      "3-11 : https://patents.google.com/patent/US10410120B1/en\n",
      "3-12 : https://patents.google.com/patent/US7890443B2/en\n",
      "3-13 : https://patents.google.com/patent/US20110311129A1/en\n",
      "3-14 : https://patents.google.com/patent/US20140270551A1/en\n",
      "3-15 : https://patents.google.com/patent/US9418319B2/en\n",
      "3-16 : https://patents.google.com/patent/CN108520229A/en\n",
      "3-17 : https://patents.google.com/patent/US10242294B2/en\n",
      "3-18 : https://patents.google.com/patent/US10366430B2/en\n",
      "3-19 : https://patents.google.com/patent/US10380741B2/en\n",
      "3-20 : https://patents.google.com/patent/US20180260415A1/en\n",
      "3-21 : https://patents.google.com/patent/US10303956B2/en\n",
      "3-22 : https://patents.google.com/patent/WO2019068141A1/en\n",
      "3-23 : https://patents.google.com/patent/WO2019136479A1/en\n",
      "3-24 : https://patents.google.com/patent/US10579924B1/en\n",
      "3-25 : https://patents.google.com/patent/US10395140B1/en\n",
      "3-26 : https://patents.google.com/patent/US10325352B1/en\n",
      "3-27 : https://patents.google.com/patent/US10410120B1/en\n",
      "3-28 : https://patents.google.com/patent/US10373323B1/en\n",
      "3-29 : https://patents.google.com/patent/US7890443B2/en\n",
      "3-30 : https://patents.google.com/patent/US20110311129A1/en\n",
      "3-31 : https://patents.google.com/patent/US20140270551A1/en\n",
      "3-32 : https://patents.google.com/patent/US9418319B2/en\n",
      "3-33 : https://patents.google.com/patent/US5995639A/en\n",
      "3-34 : https://patents.google.com/patent/US20050198661A1/en\n",
      "3-35 : https://patents.google.com/patent/US20090185723A1/en\n",
      "3-36 : https://patents.google.com/patent/US20090196467A1/en\n",
      "3-37 : https://patents.google.com/patent/US20120230545A1/en\n",
      "3-38 : https://patents.google.com/patent/US20130015946A1/en\n",
      "3-39 : https://patents.google.com/patent/US20130121584A1/en\n",
      "3-40 : https://patents.google.com/patent/US20140341422A1/en\n",
      "3-41 : https://patents.google.com/patent/US20150086087A1/en\n",
      "3-42 : https://patents.google.com/patent/US20150123967A1/en\n",
      "3-43 : https://patents.google.com/patent/US20150234942A1/en\n",
      "3-44 : https://patents.google.com/patent/US20160070956A1/en\n",
      "3-45 : https://patents.google.com/patent/US20160086020A1/en\n",
      "3-46 : https://patents.google.com/patent/US20160132718A1/en\n",
      "3-47 : https://patents.google.com/patent/US20170098124A1/en\n",
      "3-48 : https://patents.google.com/patent/US20170262695A1/en\n",
      "3-49 : https://patents.google.com/patent/US20170286752A1/en\n",
      "3-50 : https://patents.google.com/patent/US20170364750A1/en\n",
      "3-51 : https://patents.google.com/patent/US20180012092A1/en\n",
      "3-52 : https://patents.google.com/patent/US7194134B2/en\n",
      "3-53 : https://patents.google.com/patent/US7274822B2/en\n",
      "3-54 : https://patents.google.com/patent/US7596247B2/en\n",
      "3-55 : https://patents.google.com/patent/US9721148B2/en\n",
      "3-56 : https://patents.google.com/patent/US7961986B1/en\n",
      "3-57 : https://patents.google.com/patent/JP2010186216A/en\n",
      "3-58 : https://patents.google.com/patent/US20110293189A1/en\n",
      "3-59 : https://patents.google.com/patent/US9111255B2/en\n",
      "3-60 : https://patents.google.com/patent/KR101381439B1/en\n",
      "3-61 : https://patents.google.com/patent/WO2013114212A2/en\n",
      "3-62 : https://patents.google.com/patent/US8977003B1/en\n",
      "3-63 : https://patents.google.com/patent/US20150317511A1/en\n",
      "3-64 : https://patents.google.com/patent/US9158970B2/en\n",
      "abstract none\n",
      "3-65 : https://patents.google.com/patent/JP6268960B2/en\n",
      "3-66 : https://patents.google.com/patent/US9361510B2/en\n",
      "3-67 : https://patents.google.com/patent/US9852364B2/en\n",
      "3-68 : https://patents.google.com/patent/US9639742B2/en\n",
      "3-69 : https://patents.google.com/patent/CN106575367B/en\n",
      "3-70 : https://patents.google.com/patent/EP3136289A1/en\n",
      "3-71 : https://patents.google.com/patent/US10354362B2/en\n",
      "3-72 : https://patents.google.com/patent/JP2018045309A/en\n",
      "3-73 : https://patents.google.com/patent/JP2018081402A/en\n",
      "3-74 : https://patents.google.com/patent/US20160171341A1/en\n",
      "3-75 : https://patents.google.com/patent/CN106599939A/en\n",
      "3-76 : https://patents.google.com/patent/CN107220618A/en\n",
      "3-77 : https://patents.google.com/patent/CN107273836A/en\n",
      "3-78 : https://patents.google.com/patent/CN107463892A/en\n",
      "3-79 : https://patents.google.com/patent/CN105303162A/en\n",
      "3-80 : https://patents.google.com/patent/CN106778472A/en\n",
      "3-81 : https://patents.google.com/patent/US20110311129A1/en\n",
      "3-82 : https://patents.google.com/patent/US20120313955A1/en\n",
      "3-83 : https://patents.google.com/patent/US20170372174A1/en\n",
      "3-84 : https://patents.google.com/patent/US20180232471A1/en\n",
      "3-85 : https://patents.google.com/patent/US20170011281A1/en\n",
      "3-86 : https://patents.google.com/patent/US9830529B2/en\n",
      "3-87 : https://patents.google.com/patent/US9881234B2/en\n",
      "3-88 : https://patents.google.com/patent/US20180039853A1/en\n",
      "3-89 : https://patents.google.com/patent/US20180068198A1/en\n",
      "3-90 : https://patents.google.com/patent/US9947103B1/en\n",
      "3-91 : https://patents.google.com/patent/US9965719B2/en\n",
      "3-92 : https://patents.google.com/patent/US20180137642A1/en\n",
      "3-93 : https://patents.google.com/patent/US9984325B1/en\n",
      "3-94 : https://patents.google.com/patent/US20180165551A1/en\n",
      "3-95 : https://patents.google.com/patent/US10043113B1/en\n",
      "3-96 : https://patents.google.com/patent/US10095977B1/en\n",
      "3-97 : https://patents.google.com/patent/US20180321679A1/en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-98 : https://patents.google.com/patent/US20190129413A1/en\n",
      "3-99 : https://patents.google.com/patent/DE102018210632A1/en\n",
      "3-100 : https://patents.google.com/patent/US5729471A/en\n",
      "3-101 : https://patents.google.com/patent/US5995651A/en\n",
      "3-102 : https://patents.google.com/patent/US20020186144A1/en\n",
      "3-103 : https://patents.google.com/patent/US20070239494A1/en\n",
      "3-104 : https://patents.google.com/patent/WO2008081143A2/en\n",
      "3-105 : https://patents.google.com/patent/US20080183535A1/en\n",
      "3-106 : https://patents.google.com/patent/US20090116698A1/en\n",
      "3-107 : https://patents.google.com/patent/US20140254923A1/en\n",
      "3-108 : https://patents.google.com/patent/US20150023553A1/en\n",
      "3-109 : https://patents.google.com/patent/US20160173568A1/en\n",
      "3-110 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-111 : https://patents.google.com/patent/US9870649B1/en\n",
      "3-112 : https://patents.google.com/patent/US10013620B1/en\n",
      "3-113 : https://patents.google.com/patent/US20180229737A1/en\n",
      "3-114 : https://patents.google.com/patent/CN106548182A/en\n",
      "3-115 : https://patents.google.com/patent/CN107463962A/en\n",
      "3-116 : https://patents.google.com/patent/US10496895B2/en\n",
      "3-117 : https://patents.google.com/patent/US10586336B2/en\n",
      "3-118 : https://patents.google.com/patent/WO2019246250A1/en\n",
      "3-119 : https://patents.google.com/patent/US10438082B1/en\n",
      "3-120 : https://patents.google.com/patent/US10423860B1/en\n",
      "3-121 : https://patents.google.com/patent/US10430691B1/en\n",
      "3-122 : https://patents.google.com/patent/US10387752B1/en\n",
      "3-123 : https://patents.google.com/patent/US10402695B1/en\n",
      "3-124 : https://patents.google.com/patent/US10387754B1/en\n",
      "3-125 : https://patents.google.com/patent/US20170344808A1/en\n",
      "3-126 : https://patents.google.com/patent/US10322510B2/en\n",
      "3-127 : https://patents.google.com/patent/US10311321B1/en\n",
      "3-128 : https://patents.google.com/patent/US10438082B1/en\n",
      "3-129 : https://patents.google.com/patent/US10387752B1/en\n",
      "3-130 : https://patents.google.com/patent/US10430691B1/en\n",
      "3-131 : https://patents.google.com/patent/US10423860B1/en\n",
      "3-132 : https://patents.google.com/patent/US10402695B1/en\n",
      "3-133 : https://patents.google.com/patent/US10387754B1/en\n",
      "3-134 : https://patents.google.com/patent/US6671400B1/en\n",
      "3-135 : https://patents.google.com/patent/US9373057B1/en\n",
      "3-136 : https://patents.google.com/patent/US9400925B2/en\n",
      "3-137 : https://patents.google.com/patent/US9665802B2/en\n",
      "3-138 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-139 : https://patents.google.com/patent/US20170262996A1/en\n",
      "3-140 : https://patents.google.com/patent/US20170286774A1/en\n",
      "3-141 : https://patents.google.com/patent/US9785919B2/en\n",
      "3-142 : https://patents.google.com/patent/US20180114390A1/en\n",
      "3-143 : https://patents.google.com/patent/US20180129869A1/en\n",
      "3-144 : https://patents.google.com/patent/US10346717B1/en\n",
      "3-145 : https://patents.google.com/patent/US10387752B1/en\n",
      "3-146 : https://patents.google.com/patent/US10387754B1/en\n",
      "3-147 : https://patents.google.com/patent/US10402686B1/en\n",
      "3-148 : https://patents.google.com/patent/US10402695B1/en\n",
      "3-149 : https://patents.google.com/patent/US10423860B1/en\n",
      "3-150 : https://patents.google.com/patent/US10430691B1/en\n",
      "3-151 : https://patents.google.com/patent/US20160155011A1/en\n",
      "3-152 : https://patents.google.com/patent/US20160292589A1/en\n",
      "3-153 : https://patents.google.com/patent/US20160321784A1/en\n",
      "3-154 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-155 : https://patents.google.com/patent/US20180374341A1/en\n",
      "3-156 : https://patents.google.com/patent/US20190163193A1/en\n",
      "3-157 : https://patents.google.com/patent/US10572748B2/en\n",
      "3-158 : https://patents.google.com/patent/US6337692B1/en\n",
      "3-159 : https://patents.google.com/patent/US20110249073A1/en\n",
      "3-160 : https://patents.google.com/patent/US20150036942A1/en\n",
      "3-161 : https://patents.google.com/patent/US20150063708A1/en\n",
      "3-162 : https://patents.google.com/patent/US20150235073A1/en\n",
      "3-163 : https://patents.google.com/patent/US20150269733A1/en\n",
      "3-164 : https://patents.google.com/patent/US20150339811A1/en\n",
      "3-165 : https://patents.google.com/patent/US20160171331A1/en\n",
      "3-166 : https://patents.google.com/patent/US20160171285A1/en\n",
      "3-167 : https://patents.google.com/patent/US20160182874A1/en\n",
      "3-168 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-169 : https://patents.google.com/patent/US20170339417A1/en\n",
      "3-170 : https://patents.google.com/patent/US20180025235A1/en\n",
      "3-171 : https://patents.google.com/patent/US20100098295A1/en\n",
      "3-172 : https://patents.google.com/patent/US20100100268A1/en\n",
      "3-173 : https://patents.google.com/patent/US8670592B2/en\n",
      "3-174 : https://patents.google.com/patent/US20150234045A1/en\n",
      "3-175 : https://patents.google.com/patent/US20150354976A1/en\n",
      "3-176 : https://patents.google.com/patent/US20160307072A1/en\n",
      "3-177 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-178 : https://patents.google.com/patent/US20170344808A1/en\n",
      "3-179 : https://patents.google.com/patent/US20180253866A1/en\n",
      "3-180 : https://patents.google.com/patent/US20150178265A1/en\n",
      "3-181 : https://patents.google.com/patent/CN104834747A/en\n",
      "3-182 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-183 : https://patents.google.com/patent/US20060252554A1/en\n",
      "3-184 : https://patents.google.com/patent/US20070077987A1/en\n",
      "3-185 : https://patents.google.com/patent/EP1335783B1/en\n",
      "3-186 : https://patents.google.com/patent/US20170069159A1/en\n",
      "3-187 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-188 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-189 : https://patents.google.com/patent/US10311321B1/en\n",
      "3-190 : https://patents.google.com/patent/US10373323B1/en\n",
      "3-191 : https://patents.google.com/patent/US10387752B1/en\n",
      "3-192 : https://patents.google.com/patent/US10387754B1/en\n",
      "3-193 : https://patents.google.com/patent/US10395140B1/en\n",
      "3-194 : https://patents.google.com/patent/US10402628B2/en\n",
      "3-195 : https://patents.google.com/patent/US10402695B1/en\n",
      "3-196 : https://patents.google.com/patent/US10423860B1/en\n",
      "3-197 : https://patents.google.com/patent/US10430691B1/en\n",
      "3-198 : https://patents.google.com/patent/US10496899B1/en\n",
      "3-199 : https://patents.google.com/patent/US20170011281A1/en\n",
      "3-200 : https://patents.google.com/patent/US20170147905A1/en\n",
      "3-201 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-202 : https://patents.google.com/patent/US20170262996A1/en\n",
      "3-203 : https://patents.google.com/patent/US20170308770A1/en\n",
      "3-204 : https://patents.google.com/patent/US20180114055A1/en\n",
      "3-205 : https://patents.google.com/patent/US20180137642A1/en\n",
      "3-206 : https://patents.google.com/patent/US10311321B1/en\n",
      "3-207 : https://patents.google.com/patent/US10373323B1/en\n",
      "3-208 : https://patents.google.com/patent/US10395140B1/en\n",
      "3-209 : https://patents.google.com/patent/US10402692B1/en\n",
      "3-210 : https://patents.google.com/patent/US10445611B1/en\n",
      "3-211 : https://patents.google.com/patent/US10496899B1/en\n",
      "3-212 : https://patents.google.com/patent/US20170011281A1/en\n",
      "3-213 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-214 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-215 : https://patents.google.com/patent/US10424086B2/en\n",
      "3-216 : https://patents.google.com/patent/US20170169315A1/en\n",
      "3-217 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-218 : https://patents.google.com/patent/US6650779B2/en\n",
      "3-219 : https://patents.google.com/patent/WO2016145379A1/en\n",
      "3-220 : https://patents.google.com/patent/US10277950B2/en\n",
      "3-221 : https://patents.google.com/patent/US20190095842A1/en\n",
      "3-222 : https://patents.google.com/patent/US20100191391A1/en\n",
      "3-223 : https://patents.google.com/patent/US20120083974A1/en\n",
      "3-224 : https://patents.google.com/patent/US20120140061A1/en\n",
      "3-225 : https://patents.google.com/patent/US20130054106A1/en\n",
      "3-226 : https://patents.google.com/patent/US20130179382A1/en\n",
      "3-227 : https://patents.google.com/patent/US20170120803A1/en\n",
      "3-228 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-229 : https://patents.google.com/patent/JP2010524111A/en\n",
      "3-230 : https://patents.google.com/patent/JP2015064778A/en\n",
      "3-231 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-232 : https://patents.google.com/patent/US20140355861A1/en\n",
      "3-233 : https://patents.google.com/patent/US20160104058A1/en\n",
      "3-234 : https://patents.google.com/patent/US20160283841A1/en\n",
      "3-235 : https://patents.google.com/patent/US20170206431A1/en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-236 : https://patents.google.com/patent/US20170169315A1/en\n",
      "3-237 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-238 : https://patents.google.com/patent/US20060245653A1/en\n",
      "3-239 : https://patents.google.com/patent/US9202144B2/en\n",
      "3-240 : https://patents.google.com/patent/US20170011281A1/en\n",
      "3-241 : https://patents.google.com/patent/US20170132472A1/en\n",
      "3-242 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-243 : https://patents.google.com/patent/US20170220876A1/en\n",
      "3-244 : https://patents.google.com/patent/US20170294124A1/en\n",
      "3-245 : https://patents.google.com/patent/US20180129887A1/en\n",
      "3-246 : https://patents.google.com/patent/US20180137642A1/en\n",
      "3-247 : https://patents.google.com/patent/US20180158189A1/en\n",
      "3-248 : https://patents.google.com/patent/US20180165551A1/en\n",
      "3-249 : https://patents.google.com/patent/US20180253622A1/en\n",
      "3-250 : https://patents.google.com/patent/US10223610B1/en\n",
      "3-251 : https://patents.google.com/patent/US20190102646A1/en\n",
      "3-252 : https://patents.google.com/patent/US20160148079A1/en\n",
      "3-253 : https://patents.google.com/patent/US20160239706A1/en\n",
      "3-254 : https://patents.google.com/patent/US20160358337A1/en\n",
      "3-255 : https://patents.google.com/patent/US20160358069A1/en\n",
      "3-256 : https://patents.google.com/patent/US20170011281A1/en\n",
      "3-257 : https://patents.google.com/patent/US20170039436A1/en\n",
      "3-258 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-259 : https://patents.google.com/patent/US20170124409A1/en\n",
      "3-260 : https://patents.google.com/patent/US20170169315A1/en\n",
      "3-261 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-262 : https://patents.google.com/patent/US20180012374A1/en\n",
      "3-263 : https://patents.google.com/patent/US20180096457A1/en\n",
      "3-264 : https://patents.google.com/patent/US20180137642A1/en\n",
      "3-265 : https://patents.google.com/patent/US20180211403A1/en\n",
      "3-266 : https://patents.google.com/patent/US20180268234A1/en\n",
      "3-267 : https://patents.google.com/patent/US20180285659A1/en\n",
      "3-268 : https://patents.google.com/patent/US20180341872A1/en\n",
      "3-269 : https://patents.google.com/patent/US20180373975A1/en\n",
      "3-270 : https://patents.google.com/patent/US20190012548A1/en\n",
      "3-271 : https://patents.google.com/patent/US10198671B1/en\n",
      "3-272 : https://patents.google.com/patent/US20190050681A1/en\n",
      "3-273 : https://patents.google.com/patent/US20190057507A1/en\n",
      "3-274 : https://patents.google.com/patent/US20190065867A1/en\n",
      "3-275 : https://patents.google.com/patent/US20190073563A1/en\n",
      "3-276 : https://patents.google.com/patent/US20190073553A1/en\n",
      "3-277 : https://patents.google.com/patent/US10229346B1/en\n",
      "3-278 : https://patents.google.com/patent/US20190096125A1/en\n",
      "3-279 : https://patents.google.com/patent/US10572770B2/en\n",
      "3-280 : https://patents.google.com/patent/US20160148079A1/en\n",
      "3-281 : https://patents.google.com/patent/US20170011281A1/en\n",
      "3-282 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-283 : https://patents.google.com/patent/US20170124409A1/en\n",
      "3-284 : https://patents.google.com/patent/US20170169315A1/en\n",
      "3-285 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-286 : https://patents.google.com/patent/US20180096457A1/en\n",
      "3-287 : https://patents.google.com/patent/US20180137642A1/en\n",
      "3-288 : https://patents.google.com/patent/US20180211403A1/en\n",
      "3-289 : https://patents.google.com/patent/US20180268234A1/en\n",
      "3-290 : https://patents.google.com/patent/US20190012548A1/en\n",
      "3-291 : https://patents.google.com/patent/US10198671B1/en\n",
      "3-292 : https://patents.google.com/patent/US20190050681A1/en\n",
      "3-293 : https://patents.google.com/patent/US10223614B1/en\n",
      "3-294 : https://patents.google.com/patent/US20190073553A1/en\n",
      "3-295 : https://patents.google.com/patent/US10229346B1/en\n",
      "3-296 : https://patents.google.com/patent/US20160283864A1/en\n",
      "3-297 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-298 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-299 : https://patents.google.com/patent/US20170262996A1/en\n",
      "3-300 : https://patents.google.com/patent/US20170308770A1/en\n",
      "3-301 : https://patents.google.com/patent/US20180068198A1/en\n",
      "3-302 : https://patents.google.com/patent/US9934440B1/en\n",
      "3-303 : https://patents.google.com/patent/US20180096457A1/en\n",
      "3-304 : https://patents.google.com/patent/US9946960B1/en\n",
      "3-305 : https://patents.google.com/patent/US9947228B1/en\n",
      "3-306 : https://patents.google.com/patent/US20180114055A1/en\n",
      "3-307 : https://patents.google.com/patent/US20180137642A1/en\n",
      "3-308 : https://patents.google.com/patent/US9996890B1/en\n",
      "3-309 : https://patents.google.com/patent/US20180165551A1/en\n",
      "3-310 : https://patents.google.com/patent/US10002313B2/en\n",
      "3-311 : https://patents.google.com/patent/US10043113B1/en\n",
      "3-312 : https://patents.google.com/patent/US20180247405A1/en\n",
      "3-313 : https://patents.google.com/patent/US20180253622A1/en\n",
      "3-314 : https://patents.google.com/patent/US20180268292A1/en\n",
      "3-315 : https://patents.google.com/patent/US20180285686A1/en\n",
      "3-316 : https://patents.google.com/patent/US10095977B1/en\n",
      "3-317 : https://patents.google.com/patent/US20180330238A1/en\n",
      "3-318 : https://patents.google.com/patent/US20190019037A1/en\n",
      "3-319 : https://patents.google.com/patent/US10198671B1/en\n",
      "3-320 : https://patents.google.com/patent/US10223610B1/en\n",
      "3-321 : https://patents.google.com/patent/US20190073553A1/en\n",
      "3-322 : https://patents.google.com/patent/US20190072977A1/en\n",
      "3-323 : https://patents.google.com/patent/US20190073568A1/en\n",
      "3-324 : https://patents.google.com/patent/US20190108640A1/en\n",
      "3-325 : https://patents.google.com/patent/US20190130191A1/en\n",
      "3-326 : https://patents.google.com/patent/US20190130583A1/en\n",
      "3-327 : https://patents.google.com/patent/US20190164290A1/en\n",
      "3-328 : https://patents.google.com/patent/US10311321B1/en\n",
      "3-329 : https://patents.google.com/patent/US20190172223A1/en\n",
      "3-330 : https://patents.google.com/patent/US20190197331A1/en\n",
      "3-331 : https://patents.google.com/patent/US20190213438A1/en\n",
      "3-332 : https://patents.google.com/patent/US20160148079A1/en\n",
      "3-333 : https://patents.google.com/patent/US20160148080A1/en\n",
      "3-334 : https://patents.google.com/patent/US20170011281A1/en\n",
      "3-335 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-336 : https://patents.google.com/patent/US20170124409A1/en\n",
      "3-337 : https://patents.google.com/patent/US20170169315A1/en\n",
      "3-338 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-339 : https://patents.google.com/patent/US20180096457A1/en\n",
      "3-340 : https://patents.google.com/patent/US20180137642A1/en\n",
      "3-341 : https://patents.google.com/patent/US20180211403A1/en\n",
      "3-342 : https://patents.google.com/patent/US20180268234A1/en\n",
      "3-343 : https://patents.google.com/patent/US20180336469A1/en\n",
      "3-344 : https://patents.google.com/patent/US20190012548A1/en\n",
      "3-345 : https://patents.google.com/patent/US20190026917A1/en\n",
      "3-346 : https://patents.google.com/patent/US10198671B1/en\n",
      "3-347 : https://patents.google.com/patent/US20190050681A1/en\n",
      "3-348 : https://patents.google.com/patent/US10223614B1/en\n",
      "3-349 : https://patents.google.com/patent/US20190073553A1/en\n",
      "3-350 : https://patents.google.com/patent/US10229346B1/en\n",
      "3-351 : https://patents.google.com/patent/US10387740B2/en\n",
      "3-352 : https://patents.google.com/patent/US5479576A/en\n",
      "3-353 : https://patents.google.com/patent/US20160148079A1/en\n",
      "3-354 : https://patents.google.com/patent/US20160217368A1/en\n",
      "3-355 : https://patents.google.com/patent/US20170011281A1/en\n",
      "3-356 : https://patents.google.com/patent/US20170046616A1/en\n",
      "3-357 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-358 : https://patents.google.com/patent/US20170124409A1/en\n",
      "3-359 : https://patents.google.com/patent/US20170132496A1/en\n",
      "3-360 : https://patents.google.com/patent/US20170169315A1/en\n",
      "3-361 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-362 : https://patents.google.com/patent/US20180032857A1/en\n",
      "3-363 : https://patents.google.com/patent/US20180096457A1/en\n",
      "3-364 : https://patents.google.com/patent/US20180107926A1/en\n",
      "3-365 : https://patents.google.com/patent/US20180107925A1/en\n",
      "3-366 : https://patents.google.com/patent/US20180197081A1/en\n",
      "3-367 : https://patents.google.com/patent/US20180211403A1/en\n",
      "3-368 : https://patents.google.com/patent/US20180247180A1/en\n",
      "3-369 : https://patents.google.com/patent/US20180268234A1/en\n",
      "3-370 : https://patents.google.com/patent/US10127495B1/en\n",
      "3-371 : https://patents.google.com/patent/US20190012548A1/en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-372 : https://patents.google.com/patent/US20190020871A1/en\n",
      "3-373 : https://patents.google.com/patent/US10198671B1/en\n",
      "3-374 : https://patents.google.com/patent/US20190050681A1/en\n",
      "3-375 : https://patents.google.com/patent/US20190073553A1/en\n",
      "3-376 : https://patents.google.com/patent/US20190095777A1/en\n",
      "3-377 : https://patents.google.com/patent/US10560696B2/en\n",
      "3-378 : https://patents.google.com/patent/US20160148079A1/en\n",
      "3-379 : https://patents.google.com/patent/US20170011281A1/en\n",
      "3-380 : https://patents.google.com/patent/US20170124409A1/en\n",
      "3-381 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-382 : https://patents.google.com/patent/US20170132496A1/en\n",
      "3-383 : https://patents.google.com/patent/US20170169315A1/en\n",
      "3-384 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-385 : https://patents.google.com/patent/US20180032857A1/en\n",
      "3-386 : https://patents.google.com/patent/US20180096457A1/en\n",
      "3-387 : https://patents.google.com/patent/US20180107926A1/en\n",
      "3-388 : https://patents.google.com/patent/US20180107925A1/en\n",
      "3-389 : https://patents.google.com/patent/US20180197081A1/en\n",
      "3-390 : https://patents.google.com/patent/US20180211403A1/en\n",
      "3-391 : https://patents.google.com/patent/US20180247180A1/en\n",
      "3-392 : https://patents.google.com/patent/US20180268234A1/en\n",
      "3-393 : https://patents.google.com/patent/US10127495B1/en\n",
      "3-394 : https://patents.google.com/patent/US20190012548A1/en\n",
      "3-395 : https://patents.google.com/patent/US20190020871A1/en\n",
      "3-396 : https://patents.google.com/patent/US10198671B1/en\n",
      "3-397 : https://patents.google.com/patent/US20190050681A1/en\n",
      "3-398 : https://patents.google.com/patent/US20190073553A1/en\n",
      "3-399 : https://patents.google.com/patent/US20190095777A1/en\n",
      "3-400 : https://patents.google.com/patent/US20160148079A1/en\n",
      "3-401 : https://patents.google.com/patent/US20160148080A1/en\n",
      "3-402 : https://patents.google.com/patent/US20170011281A1/en\n",
      "3-403 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-404 : https://patents.google.com/patent/US20170124409A1/en\n",
      "3-405 : https://patents.google.com/patent/US20170169315A1/en\n",
      "3-406 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-407 : https://patents.google.com/patent/US20180096457A1/en\n",
      "3-408 : https://patents.google.com/patent/US20180137642A1/en\n",
      "3-409 : https://patents.google.com/patent/US20180211403A1/en\n",
      "3-410 : https://patents.google.com/patent/US20180268234A1/en\n",
      "3-411 : https://patents.google.com/patent/US20180336469A1/en\n",
      "3-412 : https://patents.google.com/patent/US20190012548A1/en\n",
      "3-413 : https://patents.google.com/patent/US20190026917A1/en\n",
      "3-414 : https://patents.google.com/patent/US10198671B1/en\n",
      "3-415 : https://patents.google.com/patent/US20190050681A1/en\n",
      "3-416 : https://patents.google.com/patent/US10223614B1/en\n",
      "3-417 : https://patents.google.com/patent/US20190073553A1/en\n",
      "3-418 : https://patents.google.com/patent/US10229346B1/en\n",
      "3-419 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-420 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-421 : https://patents.google.com/patent/US20180096457A1/en\n",
      "3-422 : https://patents.google.com/patent/US20190045168A1/en\n",
      "3-423 : https://patents.google.com/patent/US20190188525A1/en\n",
      "3-424 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-425 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-426 : https://patents.google.com/patent/US20180096457A1/en\n",
      "3-427 : https://patents.google.com/patent/US20190019050A1/en\n",
      "3-428 : https://patents.google.com/patent/US20190045168A1/en\n",
      "3-429 : https://patents.google.com/patent/US20190188525A1/en\n",
      "3-430 : https://patents.google.com/patent/US20160148079A1/en\n",
      "3-431 : https://patents.google.com/patent/US20160148080A1/en\n",
      "3-432 : https://patents.google.com/patent/US20170011281A1/en\n",
      "3-433 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-434 : https://patents.google.com/patent/US20170124409A1/en\n",
      "3-435 : https://patents.google.com/patent/US20170169315A1/en\n",
      "3-436 : https://patents.google.com/patent/US20170186176A1/en\n",
      "3-437 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-438 : https://patents.google.com/patent/US20180096457A1/en\n",
      "3-439 : https://patents.google.com/patent/US20180137642A1/en\n",
      "3-440 : https://patents.google.com/patent/US20180211403A1/en\n",
      "3-441 : https://patents.google.com/patent/US20180268234A1/en\n",
      "3-442 : https://patents.google.com/patent/US20180267997A1/en\n",
      "3-443 : https://patents.google.com/patent/US20180336469A1/en\n",
      "3-444 : https://patents.google.com/patent/US20180342061A1/en\n",
      "3-445 : https://patents.google.com/patent/US20190012548A1/en\n",
      "3-446 : https://patents.google.com/patent/US20190026917A1/en\n",
      "3-447 : https://patents.google.com/patent/US10198671B1/en\n",
      "3-448 : https://patents.google.com/patent/US20190050681A1/en\n",
      "3-449 : https://patents.google.com/patent/US10223614B1/en\n",
      "3-450 : https://patents.google.com/patent/US20190073553A1/en\n",
      "3-451 : https://patents.google.com/patent/US10229346B1/en\n",
      "3-452 : https://patents.google.com/patent/US20160104058A1/en\n",
      "3-453 : https://patents.google.com/patent/US20170011281A1/en\n",
      "3-454 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-455 : https://patents.google.com/patent/US20170147905A1/en\n",
      "3-456 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-457 : https://patents.google.com/patent/US9946960B1/en\n",
      "3-458 : https://patents.google.com/patent/US9996890B1/en\n",
      "3-459 : https://patents.google.com/patent/US20130243246A1/en\n",
      "3-460 : https://patents.google.com/patent/US20160065931A1/en\n",
      "3-461 : https://patents.google.com/patent/US20160148079A1/en\n",
      "3-462 : https://patents.google.com/patent/US20170011281A1/en\n",
      "3-463 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-464 : https://patents.google.com/patent/US20170124409A1/en\n",
      "3-465 : https://patents.google.com/patent/US20170169315A1/en\n",
      "3-466 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-467 : https://patents.google.com/patent/US20180096457A1/en\n",
      "3-468 : https://patents.google.com/patent/US20180137642A1/en\n",
      "3-469 : https://patents.google.com/patent/US10007865B1/en\n",
      "3-470 : https://patents.google.com/patent/US20180211403A1/en\n",
      "3-471 : https://patents.google.com/patent/US20180268234A1/en\n",
      "3-472 : https://patents.google.com/patent/US20190012548A1/en\n",
      "3-473 : https://patents.google.com/patent/US20190034734A1/en\n",
      "3-474 : https://patents.google.com/patent/US10198671B1/en\n",
      "3-475 : https://patents.google.com/patent/US20190050681A1/en\n",
      "3-476 : https://patents.google.com/patent/US10223614B1/en\n",
      "3-477 : https://patents.google.com/patent/US20190073553A1/en\n",
      "3-478 : https://patents.google.com/patent/US10229346B1/en\n",
      "3-479 : https://patents.google.com/patent/US20160148079A1/en\n",
      "3-480 : https://patents.google.com/patent/US20170011281A1/en\n",
      "3-481 : https://patents.google.com/patent/US20170124415A1/en\n",
      "3-482 : https://patents.google.com/patent/US20170124409A1/en\n",
      "3-483 : https://patents.google.com/patent/US20170169315A1/en\n",
      "3-484 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-485 : https://patents.google.com/patent/US20180096457A1/en\n",
      "3-486 : https://patents.google.com/patent/US20180137642A1/en\n",
      "3-487 : https://patents.google.com/patent/US10007865B1/en\n",
      "3-488 : https://patents.google.com/patent/US20180211403A1/en\n",
      "3-489 : https://patents.google.com/patent/US20180268234A1/en\n",
      "3-490 : https://patents.google.com/patent/US20180373963A1/en\n",
      "3-491 : https://patents.google.com/patent/US10169679B1/en\n",
      "3-492 : https://patents.google.com/patent/US20190012548A1/en\n",
      "3-493 : https://patents.google.com/patent/US10198671B1/en\n",
      "3-494 : https://patents.google.com/patent/US20190050673A1/en\n",
      "3-495 : https://patents.google.com/patent/US20190050681A1/en\n",
      "3-496 : https://patents.google.com/patent/US10223610B1/en\n",
      "3-497 : https://patents.google.com/patent/US10223614B1/en\n",
      "3-498 : https://patents.google.com/patent/US20190073553A1/en\n",
      "3-499 : https://patents.google.com/patent/US10229346B1/en\n",
      "3-500 : https://patents.google.com/patent/US20090202145A1/en\n",
      "3-501 : https://patents.google.com/patent/US20090324060A1/en\n",
      "3-502 : https://patents.google.com/patent/US20100296740A1/en\n",
      "3-503 : https://patents.google.com/patent/US20170185871A1/en\n",
      "3-504 : https://patents.google.com/patent/US8131065B2/en\n",
      "3-505 : https://patents.google.com/patent/US8509538B2/en\n",
      "3-506 : https://patents.google.com/patent/US8687893B2/en\n",
      "3-507 : https://patents.google.com/patent/JP2013110569A/en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-508 : https://patents.google.com/patent/US9207760B1/en\n",
      "3-509 : https://patents.google.com/patent/US9208404B2/en\n",
      "3-510 : https://patents.google.com/patent/US9443198B1/en\n",
      "3-511 : https://patents.google.com/patent/US9489598B2/en\n",
      "3-512 : https://patents.google.com/patent/US10560362B2/en\n",
      "3-513 : https://patents.google.com/patent/US10433112B2/en\n",
      "3-514 : https://patents.google.com/patent/US20140278390A1/en\n",
      "3-515 : https://patents.google.com/patent/US20170185871A1/en\n",
      "3-516 : https://patents.google.com/patent/TWI624793B/en\n",
      "3-517 : https://patents.google.com/patent/US10382770B2/en\n",
      "3-518 : https://patents.google.com/patent/CN102210559A/en\n",
      "3-519 : https://patents.google.com/patent/JP2011257805A/en\n",
      "3-520 : https://patents.google.com/patent/CN102479329A/en\n",
      "3-521 : https://patents.google.com/patent/US9207760B1/en\n",
      "3-522 : https://patents.google.com/patent/JP2014153837A/en\n",
      "abstract none\n",
      "3-523 : https://patents.google.com/patent/JP5808371B2/en\n",
      "3-524 : https://patents.google.com/patent/CN104680120B/en\n",
      "3-525 : https://patents.google.com/patent/US9443198B1/en\n",
      "3-526 : https://patents.google.com/patent/US9563855B2/en\n",
      "3-527 : https://patents.google.com/patent/US9489598B2/en\n",
      "3-528 : https://patents.google.com/patent/CN105138953B/en\n",
      "3-529 : https://patents.google.com/patent/CN106991363A/en\n",
      "3-530 : https://patents.google.com/patent/CN105760899B/en\n",
      "3-531 : https://patents.google.com/patent/JP2018096830A/en\n",
      "abstract none\n",
      "3-532 : https://patents.google.com/patent/JP3173040B2/en\n",
      "3-533 : https://patents.google.com/patent/CN1068688C/en\n",
      "3-534 : https://patents.google.com/patent/US7194114B2/en\n",
      "3-535 : https://patents.google.com/patent/US7848566B2/en\n",
      "3-536 : https://patents.google.com/patent/KR100695136B1/en\n",
      "3-537 : https://patents.google.com/patent/US20110044537A1/en\n",
      "3-538 : https://patents.google.com/patent/US20120068920A1/en\n",
      "3-539 : https://patents.google.com/patent/US20120070035A1/en\n",
      "3-540 : https://patents.google.com/patent/US20120070036A1/en\n",
      "3-541 : https://patents.google.com/patent/US20130066592A1/en\n",
      "3-542 : https://patents.google.com/patent/US8611695B1/en\n",
      "3-543 : https://patents.google.com/patent/US8649594B1/en\n",
      "3-544 : https://patents.google.com/patent/US20140149465A1/en\n",
      "3-545 : https://patents.google.com/patent/US20140270522A1/en\n",
      "3-546 : https://patents.google.com/patent/US20140321733A1/en\n",
      "3-547 : https://patents.google.com/patent/US20150127648A1/en\n",
      "3-548 : https://patents.google.com/patent/US20150154471A1/en\n",
      "3-549 : https://patents.google.com/patent/CN104732549A/en\n",
      "3-550 : https://patents.google.com/patent/CN104732483A/en\n",
      "3-551 : https://patents.google.com/patent/US9165369B1/en\n",
      "3-552 : https://patents.google.com/patent/US9361523B1/en\n",
      "3-553 : https://patents.google.com/patent/CN105678321A/en\n",
      "3-554 : https://patents.google.com/patent/CN105740799A/en\n",
      "3-555 : https://patents.google.com/patent/WO2016133767A1/en\n",
      "3-556 : https://patents.google.com/patent/US20170185871A1/en\n",
      "3-557 : https://patents.google.com/patent/US10242294B2/en\n",
      "3-558 : https://patents.google.com/patent/CN103136309B/en\n",
      "abstract none\n",
      "3-559 : https://patents.google.com/patent/JP5469216B2/en\n",
      "3-560 : https://patents.google.com/patent/US9213919B2/en\n",
      "3-561 : https://patents.google.com/patent/US10169661B2/en\n",
      "3-562 : https://patents.google.com/patent/CN104732248B/en\n",
      "3-563 : https://patents.google.com/patent/WO2017132846A1/en\n",
      "3-564 : https://patents.google.com/patent/US9892326B2/en\n",
      "3-565 : https://patents.google.com/patent/CN108509854A/en\n",
      "3-566 : https://patents.google.com/patent/US20070047838A1/en\n",
      "3-567 : https://patents.google.com/patent/US20100124361A1/en\n",
      "3-568 : https://patents.google.com/patent/US20110157355A1/en\n",
      "3-569 : https://patents.google.com/patent/US20130250050A1/en\n",
      "3-570 : https://patents.google.com/patent/US20130335571A1/en\n",
      "3-571 : https://patents.google.com/patent/US20140125806A1/en\n",
      "3-572 : https://patents.google.com/patent/US20140132758A1/en\n",
      "3-573 : https://patents.google.com/patent/US20150242709A1/en\n",
      "3-574 : https://patents.google.com/patent/US20150278579A1/en\n",
      "3-575 : https://patents.google.com/patent/US9165369B1/en\n",
      "3-576 : https://patents.google.com/patent/US20170185871A1/en\n",
      "3-577 : https://patents.google.com/patent/US10354144B2/en\n",
      "3-578 : https://patents.google.com/patent/US10430966B2/en\n",
      "3-579 : https://patents.google.com/patent/CN104412300B/en\n",
      "3-580 : https://patents.google.com/patent/RU2640322C2/en\n",
      "3-581 : https://patents.google.com/patent/JP2017208004A/en\n",
      "3-582 : https://patents.google.com/patent/US10449956B2/en\n",
      "3-583 : https://patents.google.com/patent/CN107330432A/en\n",
      "3-584 : https://patents.google.com/patent/US20140161334A1/en\n",
      "3-585 : https://patents.google.com/patent/US9165369B1/en\n",
      "3-586 : https://patents.google.com/patent/US9471836B1/en\n",
      "3-587 : https://patents.google.com/patent/US20170053375A1/en\n",
      "3-588 : https://patents.google.com/patent/US20170083788A1/en\n",
      "3-589 : https://patents.google.com/patent/CN106650637A/en\n",
      "3-590 : https://patents.google.com/patent/CN108197544A/en\n",
      "3-591 : https://patents.google.com/patent/US10262187B1/en\n",
      "assignee none\n",
      "3-592 : https://patents.google.com/patent/TWI621075B/en\n",
      "3-593 : https://patents.google.com/patent/US9984305B2/en\n",
      "3-594 : https://patents.google.com/patent/CN107169463B/en\n",
      "3-595 : https://patents.google.com/patent/CN107908536A/en\n",
      "3-596 : https://patents.google.com/patent/US5930392A/en\n",
      "3-597 : https://patents.google.com/patent/US8543519B2/en\n",
      "3-598 : https://patents.google.com/patent/US7715597B2/en\n",
      "3-599 : https://patents.google.com/patent/US8098906B2/en\n",
      "3-600 : https://patents.google.com/patent/US9020263B2/en\n",
      "3-601 : https://patents.google.com/patent/US8306942B2/en\n",
      "3-602 : https://patents.google.com/patent/US8577130B2/en\n",
      "3-603 : https://patents.google.com/patent/US8396268B2/en\n",
      "3-604 : https://patents.google.com/patent/US8860715B2/en\n",
      "3-605 : https://patents.google.com/patent/US8494285B2/en\n",
      "3-606 : https://patents.google.com/patent/US8744172B2/en\n",
      "3-607 : https://patents.google.com/patent/US9530192B2/en\n",
      "3-608 : https://patents.google.com/patent/US9122950B2/en\n",
      "3-609 : https://patents.google.com/patent/US20160357748A1/en\n",
      "3-610 : https://patents.google.com/patent/US20170185871A1/en\n",
      "3-611 : https://patents.google.com/patent/WO2019203954A1/en\n",
      "3-612 : https://patents.google.com/patent/US20170083762A1/en\n",
      "3-613 : https://patents.google.com/patent/CN106599878A/en\n",
      "3-614 : https://patents.google.com/patent/US20170206431A1/en\n",
      "3-615 : https://patents.google.com/patent/US20170286809A1/en\n",
      "3-616 : https://patents.google.com/patent/CN107562805A/en\n",
      "3-617 : https://patents.google.com/patent/US20180075290A1/en\n",
      "3-618 : https://patents.google.com/patent/CN108038540A/en\n",
      "3-619 : https://patents.google.com/patent/CN108182394A/en\n",
      "3-620 : https://patents.google.com/patent/CN108230292A/en\n",
      "3-621 : https://patents.google.com/patent/US10255522B2/en\n",
      "3-622 : https://patents.google.com/patent/US10262218B2/en\n",
      "3-623 : https://patents.google.com/patent/US10546389B2/en\n",
      "3-624 : https://patents.google.com/patent/CN106358444B/en\n",
      "3-625 : https://patents.google.com/patent/US20180211099A1/en\n",
      "3-626 : https://patents.google.com/patent/US10275684B2/en\n",
      "3-627 : https://patents.google.com/patent/GB2549554A/en\n",
      "3-628 : https://patents.google.com/patent/CN106096670B/en\n",
      "3-629 : https://patents.google.com/patent/CN106250812B/en\n",
      "3-630 : https://patents.google.com/patent/CN106295502B/en\n",
      "3-631 : https://patents.google.com/patent/CN107784315A/en\n",
      "3-632 : https://patents.google.com/patent/US20190236411A1/en\n",
      "3-633 : https://patents.google.com/patent/WO2018071424A1/en\n",
      "3-634 : https://patents.google.com/patent/US10019651B1/en\n",
      "3-635 : https://patents.google.com/patent/CN106599939A/en\n",
      "3-636 : https://patents.google.com/patent/CN107688819A/en\n",
      "3-637 : https://patents.google.com/patent/RU2651147C1/en\n",
      "3-638 : https://patents.google.com/patent/RU173468U1/en\n",
      "3-639 : https://patents.google.com/patent/CN107145833A/en\n",
      "3-640 : https://patents.google.com/patent/WO2018208939A1/en\n",
      "3-641 : https://patents.google.com/patent/US10346724B2/en\n",
      "3-642 : https://patents.google.com/patent/US10417527B2/en\n",
      "3-643 : https://patents.google.com/patent/CN107665353A/en\n",
      "3-644 : https://patents.google.com/patent/CN108012156A/en\n",
      "3-645 : https://patents.google.com/patent/CN108009509A/en\n",
      "3-646 : https://patents.google.com/patent/CN109063695A/en\n",
      "3-647 : https://patents.google.com/patent/US10402692B1/en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-648 : https://patents.google.com/patent/US10346693B1/en\n",
      "3-649 : https://patents.google.com/patent/US10395140B1/en\n",
      "3-650 : https://patents.google.com/patent/US10325352B1/en\n",
      "3-651 : https://patents.google.com/patent/US10496899B1/en\n",
      "3-652 : https://patents.google.com/patent/US10373323B1/en\n",
      "3-653 : https://patents.google.com/patent/US10373027B1/en\n",
      "3-654 : https://patents.google.com/patent/CN110222565A/en\n",
      "3-655 : https://patents.google.com/patent/US6819790B2/en\n",
      "3-656 : https://patents.google.com/patent/US7219085B2/en\n",
      "3-657 : https://patents.google.com/patent/US7603000B2/en\n",
      "3-658 : https://patents.google.com/patent/US7634137B2/en\n",
      "3-659 : https://patents.google.com/patent/US7813822B1/en\n",
      "3-660 : https://patents.google.com/patent/US8463025B2/en\n",
      "3-661 : https://patents.google.com/patent/US7006881B1/en\n",
      "3-662 : https://patents.google.com/patent/US7904187B2/en\n",
      "3-663 : https://patents.google.com/patent/US6820897B2/en\n",
      "3-664 : https://patents.google.com/patent/US8100552B2/en\n",
      "3-665 : https://patents.google.com/patent/US7319780B2/en\n",
      "3-666 : https://patents.google.com/patent/US7346196B2/en\n",
      "3-667 : https://patents.google.com/patent/US8346017B2/en\n",
      "3-668 : https://patents.google.com/patent/US8214238B1/en\n",
      "3-669 : https://patents.google.com/patent/US8441548B1/en\n",
      "Total 712 data.\n",
      "Loop 4. 13564 data will be extracted.\n",
      "Terminate.\n",
      "Total 712 data.\n",
      "CPU times: user 19min 3s, sys: 12.3 s, total: 19min 15s\n",
      "Wall time: 25min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "references = defaultdict(dict)\n",
    "cpc = defaultdict(dict)\n",
    "abstract = []\n",
    "claims = []\n",
    "description = []\n",
    "assignee = []\n",
    "pub_num = []\n",
    "priority_date = []\n",
    "new_url_list = []\n",
    "\n",
    "i=0\n",
    "\n",
    "while len(claims) <= 1000:\n",
    "  i += 1\n",
    "  if i ==1 :\n",
    "    for j, url in enumerate(url_list):\n",
    "      num = url.split(sep=\"/\")[-2]\n",
    "      pub_num.append(num)\n",
    "      tmp, references[num], cpc[num] = get_text_dict(url)\n",
    "      abstract.append(tmp[\"abstract\"])\n",
    "      claims.append(tmp[\"claims\"])\n",
    "      description.append(tmp[\"description\"])\n",
    "      assignee.append(tmp[\"assignee\"])\n",
    "      priority_date.append(tmp[\"priority_date\"])\n",
    "      print(\"{}-{} : {}\".format(i, j+1, url))\n",
    "\n",
    "  if i > 1:\n",
    "    tmp_dict = references.values()\n",
    "    for d in tmp_dict:\n",
    "      new_url_list += d[\"ForwardReferences\"]\n",
    "      new_url_list += d[\"BackwardReferences\"]\n",
    "    for url in new_url_list:\n",
    "      if url in url_list:\n",
    "        new_url_list.remove(url)\n",
    "    print(\"Loop {}. {} data will be extracted.\".format(i, len(new_url_list)))\n",
    "    if len(new_url_list) > 1000:\n",
    "      print(\"Terminate.\")\n",
    "      print(\"Total {} data.\".format(len(claims)))\n",
    "      break\n",
    "    for j, url in enumerate(new_url_list):\n",
    "      num = url.split(sep=\"/\")[-2]\n",
    "      pub_num.append(num)\n",
    "      tmp, references[num], cpc[num] = get_text_dict(url)\n",
    "      abstract.append(tmp[\"abstract\"])\n",
    "      claims.append(tmp[\"claims\"])\n",
    "      description.append(tmp[\"description\"])\n",
    "      assignee.append(tmp[\"assignee\"])\n",
    "      priority_date.append(tmp[\"priority_date\"])\n",
    "      print(\"{}-{} : {}\".format(i, j+1, url))\n",
    "    url_list += new_url_list\n",
    " \n",
    "  print(\"Total {} data.\".format(len(claims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>priority_date</th>\n",
       "      <th>assignee</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US9858496B2</td>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>Microsoft Technology Licensing LLC</td>\n",
       "      <td>Abstract Systems, methods, and computer-readab...</td>\n",
       "      <td>Claims ( 17 ) What is claimed is: 1. A method ...</td>\n",
       "      <td>Description BACKGROUND As search engine capabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US20180107866A1</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>Snap Inc</td>\n",
       "      <td>Abstract Systems, devices, media, and methods ...</td>\n",
       "      <td>Claims ( 20 ) What is claimed is: 1 . A method...</td>\n",
       "      <td>Description TECHNICAL FIELD Embodiments of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN108520229A</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>北京旷视科技有限公司</td>\n",
       "      <td>Abstract The present invention provides a kind...</td>\n",
       "      <td>Claims ( 13 ) 1. a kind of image detecting met...</td>\n",
       "      <td>Description Image detecting method, device, el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN108573228A</td>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>杭州华雁云态信息技术有限公司</td>\n",
       "      <td>Abstract A kind of electric line foreign matte...</td>\n",
       "      <td>Claims ( 10 ) 1. a kind of electric line forei...</td>\n",
       "      <td>Description A kind of electric line foreign ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US10242294B2</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>Intel Corp</td>\n",
       "      <td>Abstract An example apparatus for classifying ...</td>\n",
       "      <td>Claims ( 16 ) What is claimed is: 1. An appara...</td>\n",
       "      <td>Description BACKGROUND Various object classifi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id priority_date                            assignee  \\\n",
       "0      US9858496B2    2016-01-20  Microsoft Technology Licensing LLC   \n",
       "1  US20180107866A1    2016-10-19                            Snap Inc   \n",
       "2     CN108520229A    2018-04-04                          北京旷视科技有限公司   \n",
       "3     CN108573228A    2018-04-09                      杭州华雁云态信息技术有限公司   \n",
       "4     US10242294B2    2017-05-01                          Intel Corp   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Abstract Systems, methods, and computer-readab...   \n",
       "1  Abstract Systems, devices, media, and methods ...   \n",
       "2  Abstract The present invention provides a kind...   \n",
       "3  Abstract A kind of electric line foreign matte...   \n",
       "4  Abstract An example apparatus for classifying ...   \n",
       "\n",
       "                                              claims  \\\n",
       "0  Claims ( 17 ) What is claimed is: 1. A method ...   \n",
       "1  Claims ( 20 ) What is claimed is: 1 . A method...   \n",
       "2  Claims ( 13 ) 1. a kind of image detecting met...   \n",
       "3  Claims ( 10 ) 1. a kind of electric line forei...   \n",
       "4  Claims ( 16 ) What is claimed is: 1. An appara...   \n",
       "\n",
       "                                         description  \n",
       "0  Description BACKGROUND As search engine capabi...  \n",
       "1  Description TECHNICAL FIELD Embodiments of the...  \n",
       "2  Description Image detecting method, device, el...  \n",
       "3  Description A kind of electric line foreign ma...  \n",
       "4  Description BACKGROUND Various object classifi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"id\" : pub_num,\n",
    "    \"priority_date\": priority_date,\n",
    "    \"assignee\" : assignee,\n",
    "    \"abstract\" : abstract,\n",
    "    \"claims\" : claims,\n",
    "    \"description\" : description\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "TOP_CLAIM = re.compile(r'Claims\\ \\(\\ [0-9]{1,3}\\ \\)(.{20,}?)\\.')\n",
    "TOP_CLAIM_2 = re.compile(r'Claims\\ (.{20,}?)\\.') \n",
    "\n",
    "def extract_top_claim(text):\n",
    "    text = re.sub(\"What is claimed is: \", \"\", text)\n",
    "    m = TOP_CLAIM.search(text)\n",
    "    if m == None:\n",
    "        m = TOP_CLAIM_2.search(text)\n",
    "        if m == None:\n",
    "            return\n",
    "    text = re.sub(\"1\\.\\ \", \"\", m.group(1))\n",
    "    text = re.sub(\"1 \\.\\ \", \"\", text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"what is claimed is: \", \"\", text)\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    text = \" \".join([w for w in text.split() if not re.match(r\"^[0-9]{1,5}[a-z]$|^[0-9]{1,5}.*[0-9]$|^\\(.*\\)$|\\\\n|\\\\t|^\\\\\", w)])\n",
    "    return text\n",
    "\n",
    "def abstract_preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    text = \" \".join([w for w in text.split() if not re.match(r\"^[0-9]{1,5}[a-z]$|^[0-9]{1,5}.*[0-9]$|^\\(.*\\)$|\\\\n|\\\\t|^\\\\\", w)])    \n",
    "    return re.sub(\"^abstract \",\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"top_claims\"] = df[\"claims\"].map(extract_top_claim)\n",
    "df[\"preprocessed_abstract\"] = df[\"abstract\"].map(abstract_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>priority_date</th>\n",
       "      <th>assignee</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims</th>\n",
       "      <th>description</th>\n",
       "      <th>top_claims</th>\n",
       "      <th>preprocessed_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US9858496B2</td>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>Microsoft Technology Licensing LLC</td>\n",
       "      <td>Abstract Systems, methods, and computer-readab...</td>\n",
       "      <td>Claims ( 17 ) What is claimed is: 1. A method ...</td>\n",
       "      <td>Description BACKGROUND As search engine capabi...</td>\n",
       "      <td>a method comprising receiving an input image g...</td>\n",
       "      <td>systems methods and computerreadable media for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US20180107866A1</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>Snap Inc</td>\n",
       "      <td>Abstract Systems, devices, media, and methods ...</td>\n",
       "      <td>Claims ( 20 ) What is claimed is: 1 . A method...</td>\n",
       "      <td>Description TECHNICAL FIELD Embodiments of the...</td>\n",
       "      <td>a method comprising receiving by one or more p...</td>\n",
       "      <td>systems devices media and methods are presente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN108520229A</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>北京旷视科技有限公司</td>\n",
       "      <td>Abstract The present invention provides a kind...</td>\n",
       "      <td>Claims ( 13 ) 1. a kind of image detecting met...</td>\n",
       "      <td>Description Image detecting method, device, el...</td>\n",
       "      <td>a kind of image detecting method which is char...</td>\n",
       "      <td>the present invention provides a kind of image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN108573228A</td>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>杭州华雁云态信息技术有限公司</td>\n",
       "      <td>Abstract A kind of electric line foreign matte...</td>\n",
       "      <td>Claims ( 10 ) 1. a kind of electric line forei...</td>\n",
       "      <td>Description A kind of electric line foreign ma...</td>\n",
       "      <td>a kind of electric line foreign matter intrusi...</td>\n",
       "      <td>a kind of electric line foreign matter intrusi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US10242294B2</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>Intel Corp</td>\n",
       "      <td>Abstract An example apparatus for classifying ...</td>\n",
       "      <td>Claims ( 16 ) What is claimed is: 1. An appara...</td>\n",
       "      <td>Description BACKGROUND Various object classifi...</td>\n",
       "      <td>an apparatus for classifying target objects us...</td>\n",
       "      <td>an example apparatus for classifying target ob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id priority_date                            assignee  \\\n",
       "0      US9858496B2    2016-01-20  Microsoft Technology Licensing LLC   \n",
       "1  US20180107866A1    2016-10-19                            Snap Inc   \n",
       "2     CN108520229A    2018-04-04                          北京旷视科技有限公司   \n",
       "3     CN108573228A    2018-04-09                      杭州华雁云态信息技术有限公司   \n",
       "4     US10242294B2    2017-05-01                          Intel Corp   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Abstract Systems, methods, and computer-readab...   \n",
       "1  Abstract Systems, devices, media, and methods ...   \n",
       "2  Abstract The present invention provides a kind...   \n",
       "3  Abstract A kind of electric line foreign matte...   \n",
       "4  Abstract An example apparatus for classifying ...   \n",
       "\n",
       "                                              claims  \\\n",
       "0  Claims ( 17 ) What is claimed is: 1. A method ...   \n",
       "1  Claims ( 20 ) What is claimed is: 1 . A method...   \n",
       "2  Claims ( 13 ) 1. a kind of image detecting met...   \n",
       "3  Claims ( 10 ) 1. a kind of electric line forei...   \n",
       "4  Claims ( 16 ) What is claimed is: 1. An appara...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Description BACKGROUND As search engine capabi...   \n",
       "1  Description TECHNICAL FIELD Embodiments of the...   \n",
       "2  Description Image detecting method, device, el...   \n",
       "3  Description A kind of electric line foreign ma...   \n",
       "4  Description BACKGROUND Various object classifi...   \n",
       "\n",
       "                                          top_claims  \\\n",
       "0  a method comprising receiving an input image g...   \n",
       "1  a method comprising receiving by one or more p...   \n",
       "2  a kind of image detecting method which is char...   \n",
       "3  a kind of electric line foreign matter intrusi...   \n",
       "4  an apparatus for classifying target objects us...   \n",
       "\n",
       "                               preprocessed_abstract  \n",
       "0  systems methods and computerreadable media for...  \n",
       "1  systems devices media and methods are presente...  \n",
       "2  the present invention provides a kind of image...  \n",
       "3  a kind of electric line foreign matter intrusi...  \n",
       "4  an example apparatus for classifying target ob...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>priority_date</th>\n",
       "      <th>assignee</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims</th>\n",
       "      <th>description</th>\n",
       "      <th>top_claims</th>\n",
       "      <th>preprocessed_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>JP6268960B2</td>\n",
       "      <td>2013-11-15</td>\n",
       "      <td>オムロン株式会社</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Claims ( 8 ) An extractor for extracting featu...</td>\n",
       "      <td>Description The present invention relates to a...</td>\n",
       "      <td>an extractor for extracting feature data of th...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>JP5808371B2</td>\n",
       "      <td>2013-08-28</td>\n",
       "      <td>ヤフー株式会社</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Claims ( 11 ) A storage unit for storing infor...</td>\n",
       "      <td>Description The present invention relates to a...</td>\n",
       "      <td>a storage unit for storing information about l...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>JP3173040B2</td>\n",
       "      <td>1991-05-10</td>\n",
       "      <td>ミノルタ株式会社</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Claims ( 4 ) (57) [Claims] 1. A device for pro...</td>\n",
       "      <td>Description DETAILED DESCRIPTION OF THE INVENT...</td>\n",
       "      <td>claims a device for processing image data cons...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>JP5469216B2</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>ファナック株式会社</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Claims ( 7 ) A three-dimensional measuring mac...</td>\n",
       "      <td>Description The present invention relates to a...</td>\n",
       "      <td>a threedimensional measuring machine that meas...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id priority_date   assignee  abstract  \\\n",
       "107  JP6268960B2    2013-11-15   オムロン株式会社  abstract   \n",
       "565  JP5808371B2    2013-08-28    ヤフー株式会社  abstract   \n",
       "574  JP3173040B2    1991-05-10   ミノルタ株式会社  abstract   \n",
       "601  JP5469216B2    2012-07-31  ファナック株式会社  abstract   \n",
       "\n",
       "                                                claims  \\\n",
       "107  Claims ( 8 ) An extractor for extracting featu...   \n",
       "565  Claims ( 11 ) A storage unit for storing infor...   \n",
       "574  Claims ( 4 ) (57) [Claims] 1. A device for pro...   \n",
       "601  Claims ( 7 ) A three-dimensional measuring mac...   \n",
       "\n",
       "                                           description  \\\n",
       "107  Description The present invention relates to a...   \n",
       "565  Description The present invention relates to a...   \n",
       "574  Description DETAILED DESCRIPTION OF THE INVENT...   \n",
       "601  Description The present invention relates to a...   \n",
       "\n",
       "                                            top_claims preprocessed_abstract  \n",
       "107  an extractor for extracting feature data of th...              abstract  \n",
       "565  a storage unit for storing information about l...              abstract  \n",
       "574  claims a device for processing image data cons...              abstract  \n",
       "601  a threedimensional measuring machine that meas...              abstract  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"preprocessed_abstract\"]==\"abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>priority_date</th>\n",
       "      <th>assignee</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims</th>\n",
       "      <th>description</th>\n",
       "      <th>top_claims</th>\n",
       "      <th>preprocessed_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>JP6268960B2</td>\n",
       "      <td>2013-11-15</td>\n",
       "      <td>オムロン株式会社</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Claims ( 8 ) An extractor for extracting featu...</td>\n",
       "      <td>Description The present invention relates to a...</td>\n",
       "      <td>an extractor for extracting feature data of th...</td>\n",
       "      <td>an extractor for extracting feature data of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>JP5808371B2</td>\n",
       "      <td>2013-08-28</td>\n",
       "      <td>ヤフー株式会社</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Claims ( 11 ) A storage unit for storing infor...</td>\n",
       "      <td>Description The present invention relates to a...</td>\n",
       "      <td>a storage unit for storing information about l...</td>\n",
       "      <td>a storage unit for storing information about l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>JP3173040B2</td>\n",
       "      <td>1991-05-10</td>\n",
       "      <td>ミノルタ株式会社</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Claims ( 4 ) (57) [Claims] 1. A device for pro...</td>\n",
       "      <td>Description DETAILED DESCRIPTION OF THE INVENT...</td>\n",
       "      <td>claims a device for processing image data cons...</td>\n",
       "      <td>claims a device for processing image data cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>JP5469216B2</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>ファナック株式会社</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Claims ( 7 ) A three-dimensional measuring mac...</td>\n",
       "      <td>Description The present invention relates to a...</td>\n",
       "      <td>a threedimensional measuring machine that meas...</td>\n",
       "      <td>a threedimensional measuring machine that meas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id priority_date   assignee  abstract  \\\n",
       "107  JP6268960B2    2013-11-15   オムロン株式会社  abstract   \n",
       "565  JP5808371B2    2013-08-28    ヤフー株式会社  abstract   \n",
       "574  JP3173040B2    1991-05-10   ミノルタ株式会社  abstract   \n",
       "601  JP5469216B2    2012-07-31  ファナック株式会社  abstract   \n",
       "\n",
       "                                                claims  \\\n",
       "107  Claims ( 8 ) An extractor for extracting featu...   \n",
       "565  Claims ( 11 ) A storage unit for storing infor...   \n",
       "574  Claims ( 4 ) (57) [Claims] 1. A device for pro...   \n",
       "601  Claims ( 7 ) A three-dimensional measuring mac...   \n",
       "\n",
       "                                           description  \\\n",
       "107  Description The present invention relates to a...   \n",
       "565  Description The present invention relates to a...   \n",
       "574  Description DETAILED DESCRIPTION OF THE INVENT...   \n",
       "601  Description The present invention relates to a...   \n",
       "\n",
       "                                            top_claims  \\\n",
       "107  an extractor for extracting feature data of th...   \n",
       "565  a storage unit for storing information about l...   \n",
       "574  claims a device for processing image data cons...   \n",
       "601  a threedimensional measuring machine that meas...   \n",
       "\n",
       "                                 preprocessed_abstract  \n",
       "107  an extractor for extracting feature data of th...  \n",
       "565  a storage unit for storing information about l...  \n",
       "574  claims a device for processing image data cons...  \n",
       "601  a threedimensional measuring machine that meas...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_list = df[df[\"preprocessed_abstract\"]==\"abstract\"].index\n",
    "for ind in ind_list:\n",
    "    df[\"preprocessed_abstract\"][ind] = df[\"top_claims\"][ind]\n",
    "\n",
    "df.loc[ind_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "def dump(fname, obj):\n",
    "  with gzip.open(fname, 'wb') as f:\n",
    "     pickle.dump(obj, f)\n",
    "\n",
    "dump(\"df_20200413.pkl.gz\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'ForwardReferences': ['https://patents.google.com/patent/US20180107866A1/en',\n",
       "              'https://patents.google.com/patent/CN108520229A/en',\n",
       "              'https://patents.google.com/patent/CN108573228A/en',\n",
       "              'https://patents.google.com/patent/US10242294B2/en',\n",
       "              'https://patents.google.com/patent/US10304009B1/en',\n",
       "              'https://patents.google.com/patent/US10366430B2/en',\n",
       "              'https://patents.google.com/patent/WO2019148729A1/en',\n",
       "              'https://patents.google.com/patent/US10380741B2/en',\n",
       "              'https://patents.google.com/patent/US10262237B2/en',\n",
       "              'https://patents.google.com/patent/US20180260415A1/en',\n",
       "              'https://patents.google.com/patent/US10255525B1/en',\n",
       "              'https://patents.google.com/patent/US10303956B2/en',\n",
       "              'https://patents.google.com/patent/CN107562925A/en',\n",
       "              'https://patents.google.com/patent/WO2019068141A1/en',\n",
       "              'https://patents.google.com/patent/US10169679B1/en',\n",
       "              'https://patents.google.com/patent/US10007865B1/en',\n",
       "              'https://patents.google.com/patent/US10467501B2/en',\n",
       "              'https://patents.google.com/patent/WO2019136479A1/en',\n",
       "              'https://patents.google.com/patent/WO2019220622A1/en',\n",
       "              'https://patents.google.com/patent/US10579924B1/en',\n",
       "              'https://patents.google.com/patent/US10303981B1/en',\n",
       "              'https://patents.google.com/patent/US10438082B1/en',\n",
       "              'https://patents.google.com/patent/US10346693B1/en',\n",
       "              'https://patents.google.com/patent/US10402692B1/en',\n",
       "              'https://patents.google.com/patent/US10509987B1/en',\n",
       "              'https://patents.google.com/patent/US10395140B1/en',\n",
       "              'https://patents.google.com/patent/US10325185B1/en',\n",
       "              'https://patents.google.com/patent/US10325352B1/en',\n",
       "              'https://patents.google.com/patent/US10387753B1/en',\n",
       "              'https://patents.google.com/patent/US10410120B1/en',\n",
       "              'https://patents.google.com/patent/US10452980B1/en',\n",
       "              'https://patents.google.com/patent/US10496899B1/en',\n",
       "              'https://patents.google.com/patent/US10445611B1/en',\n",
       "              'https://patents.google.com/patent/US10373323B1/en',\n",
       "              'https://patents.google.com/patent/US10373027B1/en'],\n",
       "             'BackwardReferences': ['https://patents.google.com/patent/US7890443B2/en',\n",
       "              'https://patents.google.com/patent/US8010471B2/en',\n",
       "              'https://patents.google.com/patent/US20110311129A1/en',\n",
       "              'https://patents.google.com/patent/US20120207346A1/en',\n",
       "              'https://patents.google.com/patent/US20140270551A1/en',\n",
       "              'https://patents.google.com/patent/US9147255B1/en',\n",
       "              'https://patents.google.com/patent/US9418319B2/en']})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references[\"US9858496B2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'cpc': ['G06K9/4671',\n",
       "              'G06F16/5838',\n",
       "              'G06F16/951',\n",
       "              'G06F17/30864',\n",
       "              'G06K9/3233',\n",
       "              'G06K9/4628',\n",
       "              'G06K9/6267',\n",
       "              'G06K9/685',\n",
       "              'G06N3/0454',\n",
       "              'G06N3/084'],\n",
       "             'description': ['Extracting features based on salient regional features, e.g. Scale Invariant Feature Transform [SIFT] keypoints',\n",
       "              'Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content using colour',\n",
       "              'Indexing; Web crawling techniques',\n",
       "              '',\n",
       "              'Determination of region of interest',\n",
       "              'Integrating the filters into a hierarchical structure',\n",
       "              'Classification techniques',\n",
       "              'Involving plural approaches, e.g. verification by template match; resolving confusion among similar patterns, e.g. O & Q',\n",
       "              'Architectures, e.g. interconnection topology using a combination of multiple neural nets',\n",
       "              'Back-propagation']})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpc[\"US9858496B2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(\"references_20200413.pkl.gz\", references)\n",
    "dump(\"cpc_20200413.pkl.gz\", cpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     712.000000\n",
       "mean      796.014045\n",
       "std       226.456641\n",
       "min       162.000000\n",
       "25%       653.000000\n",
       "50%       853.000000\n",
       "75%       911.000000\n",
       "max      1631.000000\n",
       "Name: preprocessed_abstract, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"preprocessed_abstract\"].map(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create ALBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "def load(fname):\n",
    "    with gzip.open(fname, 'rb') as f:\n",
    "        r = pickle.load(f)\n",
    "        return r\n",
    "    \n",
    "df = load(\"df_20200413.pkl.gz\")\n",
    "references = load(\"references_20200413.pkl.gz\")\n",
    "cpc = load(\"cpc_20200413.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priority_date</th>\n",
       "      <th>assignee</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims</th>\n",
       "      <th>description</th>\n",
       "      <th>top_claims</th>\n",
       "      <th>preprocessed_abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US9858496B2</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>Microsoft Technology Licensing LLC</td>\n",
       "      <td>Abstract Systems, methods, and computer-readab...</td>\n",
       "      <td>Claims ( 17 ) What is claimed is: 1. A method ...</td>\n",
       "      <td>Description BACKGROUND As search engine capabi...</td>\n",
       "      <td>a method comprising receiving an input image g...</td>\n",
       "      <td>systems methods and computerreadable media for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US20180107866A1</th>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>Snap Inc</td>\n",
       "      <td>Abstract Systems, devices, media, and methods ...</td>\n",
       "      <td>Claims ( 20 ) What is claimed is: 1 . A method...</td>\n",
       "      <td>Description TECHNICAL FIELD Embodiments of the...</td>\n",
       "      <td>a method comprising receiving by one or more p...</td>\n",
       "      <td>systems devices media and methods are presente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN108520229A</th>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>北京旷视科技有限公司</td>\n",
       "      <td>Abstract The present invention provides a kind...</td>\n",
       "      <td>Claims ( 13 ) 1. a kind of image detecting met...</td>\n",
       "      <td>Description Image detecting method, device, el...</td>\n",
       "      <td>a kind of image detecting method which is char...</td>\n",
       "      <td>the present invention provides a kind of image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN108573228A</th>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>杭州华雁云态信息技术有限公司</td>\n",
       "      <td>Abstract A kind of electric line foreign matte...</td>\n",
       "      <td>Claims ( 10 ) 1. a kind of electric line forei...</td>\n",
       "      <td>Description A kind of electric line foreign ma...</td>\n",
       "      <td>a kind of electric line foreign matter intrusi...</td>\n",
       "      <td>a kind of electric line foreign matter intrusi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US10242294B2</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>Intel Corp</td>\n",
       "      <td>Abstract An example apparatus for classifying ...</td>\n",
       "      <td>Claims ( 16 ) What is claimed is: 1. An appara...</td>\n",
       "      <td>Description BACKGROUND Various object classifi...</td>\n",
       "      <td>an apparatus for classifying target objects us...</td>\n",
       "      <td>an example apparatus for classifying target ob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                priority_date                            assignee  \\\n",
       "id                                                                  \n",
       "US9858496B2        2016-01-20  Microsoft Technology Licensing LLC   \n",
       "US20180107866A1    2016-10-19                            Snap Inc   \n",
       "CN108520229A       2018-04-04                          北京旷视科技有限公司   \n",
       "CN108573228A       2018-04-09                      杭州华雁云态信息技术有限公司   \n",
       "US10242294B2       2017-05-01                          Intel Corp   \n",
       "\n",
       "                                                          abstract  \\\n",
       "id                                                                   \n",
       "US9858496B2      Abstract Systems, methods, and computer-readab...   \n",
       "US20180107866A1  Abstract Systems, devices, media, and methods ...   \n",
       "CN108520229A     Abstract The present invention provides a kind...   \n",
       "CN108573228A     Abstract A kind of electric line foreign matte...   \n",
       "US10242294B2     Abstract An example apparatus for classifying ...   \n",
       "\n",
       "                                                            claims  \\\n",
       "id                                                                   \n",
       "US9858496B2      Claims ( 17 ) What is claimed is: 1. A method ...   \n",
       "US20180107866A1  Claims ( 20 ) What is claimed is: 1 . A method...   \n",
       "CN108520229A     Claims ( 13 ) 1. a kind of image detecting met...   \n",
       "CN108573228A     Claims ( 10 ) 1. a kind of electric line forei...   \n",
       "US10242294B2     Claims ( 16 ) What is claimed is: 1. An appara...   \n",
       "\n",
       "                                                       description  \\\n",
       "id                                                                   \n",
       "US9858496B2      Description BACKGROUND As search engine capabi...   \n",
       "US20180107866A1  Description TECHNICAL FIELD Embodiments of the...   \n",
       "CN108520229A     Description Image detecting method, device, el...   \n",
       "CN108573228A     Description A kind of electric line foreign ma...   \n",
       "US10242294B2     Description BACKGROUND Various object classifi...   \n",
       "\n",
       "                                                        top_claims  \\\n",
       "id                                                                   \n",
       "US9858496B2      a method comprising receiving an input image g...   \n",
       "US20180107866A1  a method comprising receiving by one or more p...   \n",
       "CN108520229A     a kind of image detecting method which is char...   \n",
       "CN108573228A     a kind of electric line foreign matter intrusi...   \n",
       "US10242294B2     an apparatus for classifying target objects us...   \n",
       "\n",
       "                                             preprocessed_abstract  \n",
       "id                                                                  \n",
       "US9858496B2      systems methods and computerreadable media for...  \n",
       "US20180107866A1  systems devices media and methods are presente...  \n",
       "CN108520229A     the present invention provides a kind of image...  \n",
       "CN108573228A     a kind of electric line foreign matter intrusi...  \n",
       "US10242294B2     an example apparatus for classifying target ob...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "722"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cite_pair = []\n",
    "\n",
    "for num in df.index[0:43]:\n",
    "    for cited_url in references[num][\"ForwardReferences\"]:\n",
    "        text_a = df.at[num, \"preprocessed_abstract\"]\n",
    "        text_b = df.at[cited_url.split(sep=\"/\")[-2], \"preprocessed_abstract\"]\n",
    "        cite_pair.append([text_a, text_b])\n",
    "    \n",
    "    for citing_url in references[num][\"BackwardReferences\"]:\n",
    "        text_a = df.at[citing_url.split(sep=\"/\")[-2], \"preprocessed_abstract\"]\n",
    "        text_b = df.at[num, \"preprocessed_abstract\"]\n",
    "        cite_pair.append([text_a, text_b])\n",
    "\n",
    "len(cite_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "722"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "not_cite_pair = []\n",
    "\n",
    "for num in df.index[0:43]:\n",
    "    text_a = df.at[num, \"preprocessed_abstract\"]\n",
    "    cite = references[num][\"ForwardReferences\"] + references[num][\"BackwardReferences\"]\n",
    "    cite = set([s.split(sep=\"/\")[-2] for s in cite])\n",
    "    length = len(cite)\n",
    "    \n",
    "    not_cite = set(df.index[43:]) - cite\n",
    "    \n",
    "    sample = random.sample(not_cite, length)\n",
    "    for num in sample:      \n",
    "        text_b = df.at[num, \"preprocessed_abstract\"]\n",
    "        not_cite_pair.append([text_a, text_b])\n",
    "\n",
    "len(not_cite_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['systems methods and computerreadable media for providing fast and accurate object detection and classification in images are described herein in some examples a computing device can receive an input image the computing device can process the image and generate a convolutional feature map in some configurations the convolutional feature map can be processed through a region proposal network rpn to generate proposals for candidate objects in the image in various examples the computing device can process the convolutional feature map with the proposals through a fast regionbased convolutional neural network frcn proposal classifier to determine a class of each object in the image and a confidence score associated therewith the computing device can then provide a requestor with an output including the object classification andor confidence score',\n",
       "  'field image processing means substance group of inventions relates to the field of automatic image analysis device of cascade processing of a stream of images by means of convolutional neural network is offered device comprises a motion detection unit connected to a neural network filtering unit that contains generalized feature determination blocks and a decision block wherein the motion detection unit is connected in parallel with the inputs of the generalized feature determination units whose outputs are connected to the first input of the decision block second input of which is connected to the output of the motion detection unit motion detection unit is configured to receive an image stream at the input with the possibility of determining the position of image fragments with moving objects on consecutive frames and transfer of information about the position of fragments of images with moving objects to the blocks of definition of generalized features effect technical result is an increase in the reliability of automatic detection of moving objects in the field of view of the video camera due to a combination of a fast method for determining moving objects and a method of neural network processing cl 2 dwg'],\n",
       " ['systems methods and computerreadable media for providing fast and accurate object detection and classification in images are described herein in some examples a computing device can receive an input image the computing device can process the image and generate a convolutional feature map in some configurations the convolutional feature map can be processed through a region proposal network rpn to generate proposals for candidate objects in the image in various examples the computing device can process the convolutional feature map with the proposals through a fast regionbased convolutional neural network frcn proposal classifier to determine a class of each object in the image and a confidence score associated therewith the computing device can then provide a requestor with an output including the object classification andor confidence score',\n",
       "  'systems and methods are disclosed for deep learning and classifying images of objects by receiving images of objects for training or classification of the objects producing finegrained labels of the objects providing object images to a multiclass convolutional neural network cnn having a softmax layer and a final fully connected layer to explicitly model bipartitegraph labels bgls and optimizing the cnn with global backpropagation']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_cite_pair[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = cite_pair + not_cite_pair\n",
    "label = [1]*len(cite_pair) + [0]*len(not_cite_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.28 s, sys: 1.27 s, total: 4.55 s\n",
      "Wall time: 6.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import torch\n",
    "from transformers import AlbertTokenizer\n",
    "\n",
    "# torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "\n",
    "token = tokenizer.batch_encode_plus(pair, add_special_tokens=True, \n",
    "                                    return_token_type_ids=True, max_length=512, return_attention_masks=True, pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 1242,\n",
       " 3195,\n",
       " 17,\n",
       " 1428,\n",
       " 10647,\n",
       " 579,\n",
       " 941,\n",
       " 26,\n",
       " 2674,\n",
       " 1512,\n",
       " 17,\n",
       " 8137,\n",
       " 3095,\n",
       " 11643,\n",
       " 17,\n",
       " 4039,\n",
       " 19,\n",
       " 3502,\n",
       " 50,\n",
       " 745,\n",
       " 235,\n",
       " 108,\n",
       " 19,\n",
       " 109,\n",
       " 3770,\n",
       " 21,\n",
       " 10626,\n",
       " 3646,\n",
       " 92,\n",
       " 2588,\n",
       " 40,\n",
       " 6367,\n",
       " 1961,\n",
       " 14,\n",
       " 10626,\n",
       " 3646,\n",
       " 92,\n",
       " 953,\n",
       " 14,\n",
       " 1961,\n",
       " 17,\n",
       " 7920,\n",
       " 21,\n",
       " 1065,\n",
       " 16261,\n",
       " 3309,\n",
       " 192,\n",
       " 1580,\n",
       " 2942,\n",
       " 19,\n",
       " 109,\n",
       " 8091,\n",
       " 18,\n",
       " 14,\n",
       " 1065,\n",
       " 16261,\n",
       " 3309,\n",
       " 192,\n",
       " 1580,\n",
       " 2942,\n",
       " 92,\n",
       " 44,\n",
       " 16697,\n",
       " 120,\n",
       " 21,\n",
       " 632,\n",
       " 5149,\n",
       " 982,\n",
       " 13,\n",
       " 6952,\n",
       " 103,\n",
       " 20,\n",
       " 7920,\n",
       " 10869,\n",
       " 26,\n",
       " 2316,\n",
       " 3916,\n",
       " 19,\n",
       " 14,\n",
       " 1961,\n",
       " 19,\n",
       " 617,\n",
       " 3770,\n",
       " 14,\n",
       " 10626,\n",
       " 3646,\n",
       " 92,\n",
       " 953,\n",
       " 14,\n",
       " 1065,\n",
       " 16261,\n",
       " 3309,\n",
       " 192,\n",
       " 1580,\n",
       " 2942,\n",
       " 29,\n",
       " 14,\n",
       " 10869,\n",
       " 120,\n",
       " 21,\n",
       " 1512,\n",
       " 632,\n",
       " 1281,\n",
       " 1065,\n",
       " 16261,\n",
       " 3309,\n",
       " 192,\n",
       " 17371,\n",
       " 982,\n",
       " 6034,\n",
       " 9881,\n",
       " 5149,\n",
       " 718,\n",
       " 16292,\n",
       " 20,\n",
       " 3746,\n",
       " 21,\n",
       " 718,\n",
       " 16,\n",
       " 206,\n",
       " 3095,\n",
       " 19,\n",
       " 14,\n",
       " 1961,\n",
       " 17,\n",
       " 21,\n",
       " 6548,\n",
       " 1618,\n",
       " 1598,\n",
       " 80,\n",
       " 1410,\n",
       " 14,\n",
       " 10626,\n",
       " 3646,\n",
       " 92,\n",
       " 94,\n",
       " 1181,\n",
       " 21,\n",
       " 3772,\n",
       " 248,\n",
       " 29,\n",
       " 40,\n",
       " 5196,\n",
       " 215,\n",
       " 14,\n",
       " 3095,\n",
       " 4039,\n",
       " 17,\n",
       " 248,\n",
       " 6548,\n",
       " 1618,\n",
       " 3,\n",
       " 1961,\n",
       " 5511,\n",
       " 1242,\n",
       " 92,\n",
       " 468,\n",
       " 53,\n",
       " 54,\n",
       " 91,\n",
       " 8688,\n",
       " 28895,\n",
       " 20,\n",
       " 5545,\n",
       " 1961,\n",
       " 1054,\n",
       " 53,\n",
       " 54,\n",
       " 91,\n",
       " 1912,\n",
       " 4690,\n",
       " 28895,\n",
       " 20,\n",
       " 1718,\n",
       " 21,\n",
       " 4039,\n",
       " 1061,\n",
       " 30,\n",
       " 718,\n",
       " 12970,\n",
       " 1961,\n",
       " 967,\n",
       " 363,\n",
       " 14,\n",
       " 1961,\n",
       " 1054,\n",
       " 28,\n",
       " 215,\n",
       " 54,\n",
       " 52,\n",
       " 215,\n",
       " 11968,\n",
       " 3916,\n",
       " 17,\n",
       " 21,\n",
       " 575,\n",
       " 625,\n",
       " 79,\n",
       " 579,\n",
       " 3315,\n",
       " 7718,\n",
       " 13,\n",
       " 12087,\n",
       " 1136,\n",
       " 3646,\n",
       " 13420,\n",
       " 20,\n",
       " 14,\n",
       " 53,\n",
       " 54,\n",
       " 91,\n",
       " 8688,\n",
       " 14,\n",
       " 13,\n",
       " 12087,\n",
       " 1136,\n",
       " 3646,\n",
       " 25,\n",
       " 28895,\n",
       " 20,\n",
       " 8713,\n",
       " 53,\n",
       " 54,\n",
       " 91,\n",
       " 1961,\n",
       " 5511,\n",
       " 12250,\n",
       " 18,\n",
       " 26,\n",
       " 1961,\n",
       " 6978,\n",
       " 17,\n",
       " 3095,\n",
       " 11643,\n",
       " 14,\n",
       " 53,\n",
       " 54,\n",
       " 91,\n",
       " 1961,\n",
       " 5511,\n",
       " 12250,\n",
       " 18,\n",
       " 92,\n",
       " 7920,\n",
       " 21,\n",
       " 1889,\n",
       " 5093,\n",
       " 1961,\n",
       " 9565,\n",
       " 16,\n",
       " 1886,\n",
       " 1961,\n",
       " 7855,\n",
       " 452,\n",
       " 421,\n",
       " 26829,\n",
       " 4776,\n",
       " 5808,\n",
       " 17,\n",
       " 8544,\n",
       " 967,\n",
       " 363,\n",
       " 53,\n",
       " 54,\n",
       " 91,\n",
       " 16,\n",
       " 14,\n",
       " 1886,\n",
       " 1961,\n",
       " 7855,\n",
       " 452,\n",
       " 421,\n",
       " 26829,\n",
       " 4776,\n",
       " 1381,\n",
       " 14,\n",
       " 4039,\n",
       " 1061,\n",
       " 1181,\n",
       " 14,\n",
       " 967,\n",
       " 28,\n",
       " 6367,\n",
       " 20,\n",
       " 14,\n",
       " 4039,\n",
       " 1061,\n",
       " 17,\n",
       " 2588,\n",
       " 40,\n",
       " 5196,\n",
       " 26928,\n",
       " 16,\n",
       " 3916,\n",
       " 11968,\n",
       " 363,\n",
       " 14,\n",
       " 1961,\n",
       " 1054,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token[\"input_ids\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PairDataset(Dataset):\n",
    "    def __init__(self, input_ids, token_type_ids, attention_mask, label):\n",
    "        self.input_ids = input_ids\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        one_token = self.input_ids[idx]\n",
    "        one_token_type = self.token_type_ids[idx]\n",
    "        one_mask = self.attention_mask[idx]\n",
    "        one_label = self.label[idx]\n",
    "\n",
    "#         device = torch.device(\"cuda\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        sample = {'input_ids': torch.tensor(one_token, device=device), \n",
    "                'token_type_ids': torch.tensor(one_token_type, device=device), \n",
    "                'attention_mask': torch.tensor(one_mask, device=device), \n",
    "                'label': torch.tensor(one_label, device=device)\n",
    "                }\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairDataset(token[\"input_ids\"], token[\"token_type_ids\"], token[\"attention_mask\"], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1444, 512), (1444, 512), (1444, 512), (1444,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(token[\"input_ids\"]).shape, np.array(token[\"token_type_ids\"]).shape, np.array(token[\"attention_mask\"]).shape, np.array(label).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertForSequenceClassification(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AlbertForSequenceClassification\n",
    "\n",
    "model =  AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels = 2)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /home/susumu/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages (0.0)\r\n",
      "Requirement already satisfied: scikit-learn in /home/susumu/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages (from sklearn) (0.22.2.post1)\r\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/susumu/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.4.1)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /home/susumu/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages (from scikit-learn->sklearn) (0.14.1)\r\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/susumu/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.18.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-502619807a84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m         )\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         )\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers_per_group\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgroup_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers_per_group\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             )\n\u001b[1;32m    346\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_group_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbert_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malbert_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/patent_search-Vj6LIUoQ/lib/python3.6/site-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_layer_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "total_loss = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    pred = []\n",
    "    gt = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        input_ids = data[\"input_ids\"]\n",
    "        token_type_ids = data[\"token_type_ids\"]\n",
    "        attention_mask = data[\"attention_mask\"]\n",
    "        labels = data[\"label\"]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss, logits = outputs[:2]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "        if i % 100 == 99:    # print every 100 mini-batches (400 pairs)\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    prob = torch.softmax(logits, dim=1).tolist()\n",
    "    pred += [int(np.argmax(elm)) for elm in prob]\n",
    "    gt += [int(elm) for elm in labels]\n",
    "    print(classification_report(gt, pred, target_names=[\"not_cite\", \"cite\"]))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training on Colab\n",
    "\n",
    "https://colab.research.google.com/drive/1XPYkvmJSxwKeDGWGuj-MnlvQYwWuZHNg?hl=ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priority_date</th>\n",
       "      <th>assignee</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims</th>\n",
       "      <th>description</th>\n",
       "      <th>top_claims</th>\n",
       "      <th>preprocessed_abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US9858496B2</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>Microsoft Technology Licensing LLC</td>\n",
       "      <td>Abstract Systems, methods, and computer-readab...</td>\n",
       "      <td>Claims ( 17 ) What is claimed is: 1. A method ...</td>\n",
       "      <td>Description BACKGROUND As search engine capabi...</td>\n",
       "      <td>a method comprising receiving an input image g...</td>\n",
       "      <td>systems methods and computerreadable media for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US20180107866A1</th>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>Snap Inc</td>\n",
       "      <td>Abstract Systems, devices, media, and methods ...</td>\n",
       "      <td>Claims ( 20 ) What is claimed is: 1 . A method...</td>\n",
       "      <td>Description TECHNICAL FIELD Embodiments of the...</td>\n",
       "      <td>a method comprising receiving by one or more p...</td>\n",
       "      <td>systems devices media and methods are presente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN108520229A</th>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>北京旷视科技有限公司</td>\n",
       "      <td>Abstract The present invention provides a kind...</td>\n",
       "      <td>Claims ( 13 ) 1. a kind of image detecting met...</td>\n",
       "      <td>Description Image detecting method, device, el...</td>\n",
       "      <td>a kind of image detecting method which is char...</td>\n",
       "      <td>the present invention provides a kind of image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN108573228A</th>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>杭州华雁云态信息技术有限公司</td>\n",
       "      <td>Abstract A kind of electric line foreign matte...</td>\n",
       "      <td>Claims ( 10 ) 1. a kind of electric line forei...</td>\n",
       "      <td>Description A kind of electric line foreign ma...</td>\n",
       "      <td>a kind of electric line foreign matter intrusi...</td>\n",
       "      <td>a kind of electric line foreign matter intrusi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US10242294B2</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>Intel Corp</td>\n",
       "      <td>Abstract An example apparatus for classifying ...</td>\n",
       "      <td>Claims ( 16 ) What is claimed is: 1. An appara...</td>\n",
       "      <td>Description BACKGROUND Various object classifi...</td>\n",
       "      <td>an apparatus for classifying target objects us...</td>\n",
       "      <td>an example apparatus for classifying target ob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                priority_date                            assignee  \\\n",
       "id                                                                  \n",
       "US9858496B2        2016-01-20  Microsoft Technology Licensing LLC   \n",
       "US20180107866A1    2016-10-19                            Snap Inc   \n",
       "CN108520229A       2018-04-04                          北京旷视科技有限公司   \n",
       "CN108573228A       2018-04-09                      杭州华雁云态信息技术有限公司   \n",
       "US10242294B2       2017-05-01                          Intel Corp   \n",
       "\n",
       "                                                          abstract  \\\n",
       "id                                                                   \n",
       "US9858496B2      Abstract Systems, methods, and computer-readab...   \n",
       "US20180107866A1  Abstract Systems, devices, media, and methods ...   \n",
       "CN108520229A     Abstract The present invention provides a kind...   \n",
       "CN108573228A     Abstract A kind of electric line foreign matte...   \n",
       "US10242294B2     Abstract An example apparatus for classifying ...   \n",
       "\n",
       "                                                            claims  \\\n",
       "id                                                                   \n",
       "US9858496B2      Claims ( 17 ) What is claimed is: 1. A method ...   \n",
       "US20180107866A1  Claims ( 20 ) What is claimed is: 1 . A method...   \n",
       "CN108520229A     Claims ( 13 ) 1. a kind of image detecting met...   \n",
       "CN108573228A     Claims ( 10 ) 1. a kind of electric line forei...   \n",
       "US10242294B2     Claims ( 16 ) What is claimed is: 1. An appara...   \n",
       "\n",
       "                                                       description  \\\n",
       "id                                                                   \n",
       "US9858496B2      Description BACKGROUND As search engine capabi...   \n",
       "US20180107866A1  Description TECHNICAL FIELD Embodiments of the...   \n",
       "CN108520229A     Description Image detecting method, device, el...   \n",
       "CN108573228A     Description A kind of electric line foreign ma...   \n",
       "US10242294B2     Description BACKGROUND Various object classifi...   \n",
       "\n",
       "                                                        top_claims  \\\n",
       "id                                                                   \n",
       "US9858496B2      a method comprising receiving an input image g...   \n",
       "US20180107866A1  a method comprising receiving by one or more p...   \n",
       "CN108520229A     a kind of image detecting method which is char...   \n",
       "CN108573228A     a kind of electric line foreign matter intrusi...   \n",
       "US10242294B2     an apparatus for classifying target objects us...   \n",
       "\n",
       "                                             preprocessed_abstract  \n",
       "id                                                                  \n",
       "US9858496B2      systems methods and computerreadable media for...  \n",
       "US20180107866A1  systems devices media and methods are presente...  \n",
       "CN108520229A     the present invention provides a kind of image...  \n",
       "CN108573228A     a kind of electric line foreign matter intrusi...  \n",
       "US10242294B2     an example apparatus for classifying target ob...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priority_date</th>\n",
       "      <th>assignee</th>\n",
       "      <th>preprocessed_abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US9858496B2</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>Microsoft Technology Licensing LLC</td>\n",
       "      <td>systems methods and computerreadable media for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US20180107866A1</th>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>Snap Inc</td>\n",
       "      <td>systems devices media and methods are presente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN108520229A</th>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>北京旷视科技有限公司</td>\n",
       "      <td>the present invention provides a kind of image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN108573228A</th>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>杭州华雁云态信息技术有限公司</td>\n",
       "      <td>a kind of electric line foreign matter intrusi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US10242294B2</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>Intel Corp</td>\n",
       "      <td>an example apparatus for classifying target ob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                priority_date                            assignee  \\\n",
       "id                                                                  \n",
       "US9858496B2        2016-01-20  Microsoft Technology Licensing LLC   \n",
       "US20180107866A1    2016-10-19                            Snap Inc   \n",
       "CN108520229A       2018-04-04                          北京旷视科技有限公司   \n",
       "CN108573228A       2018-04-09                      杭州华雁云态信息技术有限公司   \n",
       "US10242294B2       2017-05-01                          Intel Corp   \n",
       "\n",
       "                                             preprocessed_abstract  \n",
       "id                                                                  \n",
       "US9858496B2      systems methods and computerreadable media for...  \n",
       "US20180107866A1  systems devices media and methods are presente...  \n",
       "CN108520229A     the present invention provides a kind of image...  \n",
       "CN108573228A     a kind of electric line foreign matter intrusi...  \n",
       "US10242294B2     an example apparatus for classifying target ob...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part = df[[\"priority_date\", \"assignee\", \"preprocessed_abstract\"]]\n",
    "df_part.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((433, 7), (433, 3))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df_part.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "def dump(fname, obj):\n",
    "  with gzip.open(fname, 'wb') as f:\n",
    "     pickle.dump(obj, f)\n",
    "        \n",
    "dump(\"df_part_20200413.pkl.gz\", df_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpc_20200413.pkl.gz  df_part_20200413.pkl.gz  references_20200413.pkl.gz\r\n",
      "df_20200413.pkl.gz   patent_search.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertForSequenceClassification(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AlbertForSequenceClassification\n",
    "\n",
    "model = AlbertForSequenceClassification.from_pretrained('./', output_hidden_states=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 46.746421\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PairDataset(Dataset):\n",
    "    def __init__(self, input_ids, token_type_ids, attention_mask):\n",
    "        self.input_ids = input_ids\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.attention_mask = attention_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        one_token = self.input_ids[idx]\n",
    "        one_token_type = self.token_type_ids[idx]\n",
    "        one_mask = self.attention_mask[idx]\n",
    "\n",
    "#         device = torch.device(\"cuda\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        sample = {'input_ids': torch.tensor(one_token, device=device), \n",
    "                'token_type_ids': torch.tensor(one_token_type, device=device), \n",
    "                'attention_mask': torch.tensor(one_mask, device=device)\n",
    "                }\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prior work on object detection repurposes classifiers to perform detection instead we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities a single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation since the whole detection pipeline is a single network it can be optimized endtoend directly on detection performance'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = \"Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance.\"\n",
    "\n",
    "input_sentence = abstract_preprocess(input_sentence)\n",
    "input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_pair(input_sentence):\n",
    "    input_sentence = abstract_preprocess(input_sentence)\n",
    "    pair = []\n",
    "    for num in df.index:\n",
    "        text_a = df.at[num, \"preprocessed_abstract\"]\n",
    "        text_b = input_sentence\n",
    "        pair.append([text_a, text_b])\n",
    "    \n",
    "    return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pair = set_pair(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizer\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "\n",
    "token = tokenizer.batch_encode_plus(test_pair, add_special_tokens=True, \n",
    "                                    return_token_type_ids=True, max_length=512, return_attention_masks=True, pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PairDataset(token[\"input_ids\"], token[\"token_type_ids\"], token[\"attention_mask\"])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATen/Parallel:\n",
      "\tat::get_num_threads() : 4\n",
      "\tat::get_num_interop_threads() : 2\n",
      "OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "\tomp_get_max_threads() : 4\n",
      "Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "\tmkl_get_max_threads() : 4\n",
      "Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "std::thread::hardware_concurrency() : 4\n",
      "Environment variables:\n",
      "\tOMP_NUM_THREADS : [not set]\n",
      "\tMKL_NUM_THREADS : [not set]\n",
      "ATen parallel backend: OpenMP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(multiprocessing.cpu_count())\n",
    "print(torch.__config__.parallel_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 768])\n",
      "CPU times: user 15.8 s, sys: 1.78 s, total: 17.6 s\n",
      "Wall time: 4.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataloader, 0):\n",
    "        input_ids = data[\"input_ids\"]\n",
    "        token_type_ids = data[\"token_type_ids\"]\n",
    "        attention_mask = data[\"attention_mask\"]\n",
    "\n",
    "        outputs = model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "        print(outputs[1][-1].mean(axis=1).shape)\n",
    "        break\n",
    "        logits, = outputs\n",
    "        prob += torch.softmax(logits, dim=1).tolist()\n",
    "        \n",
    "        if i%10==9:\n",
    "            print(\"{} done\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(218, 0.9893274307250977),\n",
       " (376, 0.9882809519767761),\n",
       " (162, 0.9878667593002319),\n",
       " (375, 0.9867842197418213),\n",
       " (81, 0.986143946647644),\n",
       " (217, 0.986143946647644),\n",
       " (186, 0.9860714077949524),\n",
       " (250, 0.9858617782592773),\n",
       " (288, 0.9857050180435181),\n",
       " (219, 0.9846290349960327)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = [(i, elm[1]) for i, elm in enumerate(prob)]\n",
    "p = sorted(p, key=lambda x:x[1], reverse=True)\n",
    "p[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010672561824321747, 0.9893274307250977]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[218]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priority_date</th>\n",
       "      <th>assignee</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims</th>\n",
       "      <th>description</th>\n",
       "      <th>top_claims</th>\n",
       "      <th>preprocessed_abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US20180211403A1</th>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>Ford Global Technologies LLC</td>\n",
       "      <td>Abstract According to one embodiment, a system...</td>\n",
       "      <td>Claims ( 20 ) 1 . A method comprising: determi...</td>\n",
       "      <td>Description TECHNICAL FIELD The disclosure rel...</td>\n",
       "      <td>a method comprising determining using one or m...</td>\n",
       "      <td>according to one embodiment a system includes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US8396268B2</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>Oxford University Innovation Ltd</td>\n",
       "      <td>Abstract A method for processing a sequence of...</td>\n",
       "      <td>Claims ( 39 ) 1. A method of determining a plu...</td>\n",
       "      <td>Description BACKGROUND OF INVENTION Various sy...</td>\n",
       "      <td>a method of determining a plurality of relatio...</td>\n",
       "      <td>a method for processing a sequence of images i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US20160182874A1</th>\n",
       "      <td>2014-12-22</td>\n",
       "      <td>Conbraco Industries Inc</td>\n",
       "      <td>Abstract An apparatus includes a plurality of ...</td>\n",
       "      <td>Claims ( 20 ) 1 . An apparatus, comprising: a ...</td>\n",
       "      <td>Description FIELD OF THE DISCLOSURE The presen...</td>\n",
       "      <td>an apparatus comprising a plurality of camera ...</td>\n",
       "      <td>an apparatus includes a plurality of camera un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US8577130B2</th>\n",
       "      <td>2009-03-16</td>\n",
       "      <td>Siemens Medical Solutions USA Inc</td>\n",
       "      <td>Abstract Described herein is a technology for ...</td>\n",
       "      <td>Claims ( 23 ) The invention claimed is: 1. A m...</td>\n",
       "      <td>Description CROSS-REFERENCE TO RELATED APPLICA...</td>\n",
       "      <td>the invention claimed is 1</td>\n",
       "      <td>described herein is a technology for facilitat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US10354362B2</th>\n",
       "      <td>2016-09-08</td>\n",
       "      <td>Carnegie Mellon University</td>\n",
       "      <td>Abstract Methods of detecting an object in an ...</td>\n",
       "      <td>Claims ( 20 ) What is claimed is: 1. A method ...</td>\n",
       "      <td>Description RELATED APPLICATION DATA This appl...</td>\n",
       "      <td>a method of processing an image to detect the ...</td>\n",
       "      <td>methods of detecting an object in an image usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US20180096457A1</th>\n",
       "      <td>2016-09-08</td>\n",
       "      <td>Carnegie Mellon University</td>\n",
       "      <td>Abstract Methods of detecting an object in an ...</td>\n",
       "      <td>Claims ( 20 ) What is claimed is: 1 . A method...</td>\n",
       "      <td>Description RELATED APPLICATION DATA This appl...</td>\n",
       "      <td>a method of processing an image to detect the ...</td>\n",
       "      <td>methods of detecting an object in an image usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WO2016145379A1</th>\n",
       "      <td>2015-03-12</td>\n",
       "      <td>William Marsh Rice University</td>\n",
       "      <td>Abstract A mechanism for compiling a generativ...</td>\n",
       "      <td>Claims CLAIMS What is claimed is: 1. A compute...</td>\n",
       "      <td>Description TITLE: Automated Compilation of Pr...</td>\n",
       "      <td>claims a computerimplemented method for constr...</td>\n",
       "      <td>a mechanism for compiling a generative descrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US20190164290A1</th>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>Intel Corp</td>\n",
       "      <td>Abstract Techniques related to implementing fu...</td>\n",
       "      <td>Claims ( 24 ) 1 - 29 . (canceled) 30 . A compu...</td>\n",
       "      <td>Description BACKGROUND Semantic image segmenta...</td>\n",
       "      <td>1 canceled</td>\n",
       "      <td>techniques related to implementing fully convo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US8687893B2</th>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>Microsoft Corp</td>\n",
       "      <td>Abstract Classification algorithm optimization...</td>\n",
       "      <td>Claims ( 20 ) The invention claimed is: 1. A c...</td>\n",
       "      <td>Description BACKGROUND Classification algorith...</td>\n",
       "      <td>the invention claimed is 1</td>\n",
       "      <td>classification algorithm optimization is descr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US20180268234A1</th>\n",
       "      <td>2016-10-10</td>\n",
       "      <td>Gyrfalcon Technology Inc</td>\n",
       "      <td>Abstract A deep learning object detection and ...</td>\n",
       "      <td>Claims ( 19 ) What is claimed is: 1 . A deep l...</td>\n",
       "      <td>Description CROSS REFERENCE TO RELATED APPLICA...</td>\n",
       "      <td>a deep learning object detection and recogniti...</td>\n",
       "      <td>a deep learning object detection and recogniti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                priority_date                           assignee  \\\n",
       "id                                                                 \n",
       "US20180211403A1    2017-01-20       Ford Global Technologies LLC   \n",
       "US8396268B2        2010-03-31   Oxford University Innovation Ltd   \n",
       "US20160182874A1    2014-12-22            Conbraco Industries Inc   \n",
       "US8577130B2        2009-03-16  Siemens Medical Solutions USA Inc   \n",
       "US10354362B2       2016-09-08         Carnegie Mellon University   \n",
       "US20180096457A1    2016-09-08         Carnegie Mellon University   \n",
       "WO2016145379A1     2015-03-12      William Marsh Rice University   \n",
       "US20190164290A1    2016-08-25                         Intel Corp   \n",
       "US8687893B2        2011-03-31                     Microsoft Corp   \n",
       "US20180268234A1    2016-10-10           Gyrfalcon Technology Inc   \n",
       "\n",
       "                                                          abstract  \\\n",
       "id                                                                   \n",
       "US20180211403A1  Abstract According to one embodiment, a system...   \n",
       "US8396268B2      Abstract A method for processing a sequence of...   \n",
       "US20160182874A1  Abstract An apparatus includes a plurality of ...   \n",
       "US8577130B2      Abstract Described herein is a technology for ...   \n",
       "US10354362B2     Abstract Methods of detecting an object in an ...   \n",
       "US20180096457A1  Abstract Methods of detecting an object in an ...   \n",
       "WO2016145379A1   Abstract A mechanism for compiling a generativ...   \n",
       "US20190164290A1  Abstract Techniques related to implementing fu...   \n",
       "US8687893B2      Abstract Classification algorithm optimization...   \n",
       "US20180268234A1  Abstract A deep learning object detection and ...   \n",
       "\n",
       "                                                            claims  \\\n",
       "id                                                                   \n",
       "US20180211403A1  Claims ( 20 ) 1 . A method comprising: determi...   \n",
       "US8396268B2      Claims ( 39 ) 1. A method of determining a plu...   \n",
       "US20160182874A1  Claims ( 20 ) 1 . An apparatus, comprising: a ...   \n",
       "US8577130B2      Claims ( 23 ) The invention claimed is: 1. A m...   \n",
       "US10354362B2     Claims ( 20 ) What is claimed is: 1. A method ...   \n",
       "US20180096457A1  Claims ( 20 ) What is claimed is: 1 . A method...   \n",
       "WO2016145379A1   Claims CLAIMS What is claimed is: 1. A compute...   \n",
       "US20190164290A1  Claims ( 24 ) 1 - 29 . (canceled) 30 . A compu...   \n",
       "US8687893B2      Claims ( 20 ) The invention claimed is: 1. A c...   \n",
       "US20180268234A1  Claims ( 19 ) What is claimed is: 1 . A deep l...   \n",
       "\n",
       "                                                       description  \\\n",
       "id                                                                   \n",
       "US20180211403A1  Description TECHNICAL FIELD The disclosure rel...   \n",
       "US8396268B2      Description BACKGROUND OF INVENTION Various sy...   \n",
       "US20160182874A1  Description FIELD OF THE DISCLOSURE The presen...   \n",
       "US8577130B2      Description CROSS-REFERENCE TO RELATED APPLICA...   \n",
       "US10354362B2     Description RELATED APPLICATION DATA This appl...   \n",
       "US20180096457A1  Description RELATED APPLICATION DATA This appl...   \n",
       "WO2016145379A1   Description TITLE: Automated Compilation of Pr...   \n",
       "US20190164290A1  Description BACKGROUND Semantic image segmenta...   \n",
       "US8687893B2      Description BACKGROUND Classification algorith...   \n",
       "US20180268234A1  Description CROSS REFERENCE TO RELATED APPLICA...   \n",
       "\n",
       "                                                        top_claims  \\\n",
       "id                                                                   \n",
       "US20180211403A1  a method comprising determining using one or m...   \n",
       "US8396268B2      a method of determining a plurality of relatio...   \n",
       "US20160182874A1  an apparatus comprising a plurality of camera ...   \n",
       "US8577130B2                             the invention claimed is 1   \n",
       "US10354362B2     a method of processing an image to detect the ...   \n",
       "US20180096457A1  a method of processing an image to detect the ...   \n",
       "WO2016145379A1   claims a computerimplemented method for constr...   \n",
       "US20190164290A1                                         1 canceled   \n",
       "US8687893B2                             the invention claimed is 1   \n",
       "US20180268234A1  a deep learning object detection and recogniti...   \n",
       "\n",
       "                                             preprocessed_abstract  \n",
       "id                                                                  \n",
       "US20180211403A1  according to one embodiment a system includes ...  \n",
       "US8396268B2      a method for processing a sequence of images i...  \n",
       "US20160182874A1  an apparatus includes a plurality of camera un...  \n",
       "US8577130B2      described herein is a technology for facilitat...  \n",
       "US10354362B2     methods of detecting an object in an image usi...  \n",
       "US20180096457A1  methods of detecting an object in an image usi...  \n",
       "WO2016145379A1   a mechanism for compiling a generative descrip...  \n",
       "US20190164290A1  techniques related to implementing fully convo...  \n",
       "US8687893B2      classification algorithm optimization is descr...  \n",
       "US20180268234A1  a deep learning object detection and recogniti...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[ [t[0] for t in p[0:10]] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priority_date</th>\n",
       "      <th>assignee</th>\n",
       "      <th>abstract</th>\n",
       "      <th>preprocessed_abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US9858496B2</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>Microsoft Technology Licensing LLC</td>\n",
       "      <td>Abstract Systems, methods, and computer-readab...</td>\n",
       "      <td>systems methods and computerreadable media for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US20180107866A1</th>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>Snap Inc</td>\n",
       "      <td>Abstract Systems, devices, media, and methods ...</td>\n",
       "      <td>systems devices media and methods are presente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN108520229A</th>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>北京旷视科技有限公司</td>\n",
       "      <td>Abstract The present invention provides a kind...</td>\n",
       "      <td>the present invention provides a kind of image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN108573228A</th>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>杭州华雁云态信息技术有限公司</td>\n",
       "      <td>Abstract A kind of electric line foreign matte...</td>\n",
       "      <td>a kind of electric line foreign matter intrusi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US10242294B2</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>Intel Corp</td>\n",
       "      <td>Abstract An example apparatus for classifying ...</td>\n",
       "      <td>an example apparatus for classifying target ob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                priority_date                            assignee  \\\n",
       "id                                                                  \n",
       "US9858496B2        2016-01-20  Microsoft Technology Licensing LLC   \n",
       "US20180107866A1    2016-10-19                            Snap Inc   \n",
       "CN108520229A       2018-04-04                          北京旷视科技有限公司   \n",
       "CN108573228A       2018-04-09                      杭州华雁云态信息技术有限公司   \n",
       "US10242294B2       2017-05-01                          Intel Corp   \n",
       "\n",
       "                                                          abstract  \\\n",
       "id                                                                   \n",
       "US9858496B2      Abstract Systems, methods, and computer-readab...   \n",
       "US20180107866A1  Abstract Systems, devices, media, and methods ...   \n",
       "CN108520229A     Abstract The present invention provides a kind...   \n",
       "CN108573228A     Abstract A kind of electric line foreign matte...   \n",
       "US10242294B2     Abstract An example apparatus for classifying ...   \n",
       "\n",
       "                                             preprocessed_abstract  \n",
       "id                                                                  \n",
       "US9858496B2      systems methods and computerreadable media for...  \n",
       "US20180107866A1  systems devices media and methods are presente...  \n",
       "CN108520229A     the present invention provides a kind of image...  \n",
       "CN108573228A     a kind of electric line foreign matter intrusi...  \n",
       "US10242294B2     an example apparatus for classifying target ob...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part = df[[\"priority_date\", \"assignee\", \"abstract\", \"preprocessed_abstract\"]]\n",
    "df_part.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "def dump(fname, obj):\n",
    "  with gzip.open(fname, 'wb') as f:\n",
    "     pickle.dump(obj, f)\n",
    "\n",
    "dump(\"df_part_20200413.pkl.gz\", df_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALBERT vector with triplet loss model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "def load(fname):\n",
    "    with gzip.open(fname, 'rb') as f:\n",
    "        r = pickle.load(f)\n",
    "        return r\n",
    "    \n",
    "df = load(\"df_20200413.pkl.gz\")\n",
    "references = load(\"references_20200413.pkl.gz\")\n",
    "ALBERT_vec = load(\"ALBERT_vec.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertModel(\n",
       "  (embeddings): AlbertEmbeddings(\n",
       "    (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 128)\n",
       "    (token_type_embeddings): Embedding(2, 128)\n",
       "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (encoder): AlbertTransformer(\n",
       "    (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "    (albert_layer_groups): ModuleList(\n",
       "      (0): AlbertLayerGroup(\n",
       "        (albert_layers): ModuleList(\n",
       "          (0): AlbertLayer(\n",
       "            (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (attention): AlbertAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (pooler_activation): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AlbertModel\n",
    "\n",
    "model = AlbertModel.from_pretrained('./')\n",
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 250)\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        self.fc2 = nn.Linear(250, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.normalize(x)\n",
    "\n",
    "net = Net(input_size=768, output_size=100)\n",
    "net.load_state_dict(torch.load(\"./net.model\", map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we apply a single neural network to the full image this network divides the image into regions and predicts bounding boxes and probabilities for each region these bounding boxes are weighted by the predicted probabilities'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = \"We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities.\"\n",
    "input_sentence =abstract_preprocess(input_sentence)\n",
    "input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f640125a8ed0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlbertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'albert-base-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m token = torch.tensor(tokenizer.encode(input_sentence, \n\u001b[0m\u001b[1;32m      6\u001b[0m                          \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                          \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_sentence' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AlbertTokenizer\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "\n",
    "token = torch.tensor(tokenizer.encode(input_sentence, \n",
    "                         add_special_tokens=True, \n",
    "                         max_length=256, \n",
    "                         pad_to_max_length=True)).unsqueeze(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,    95,  5645,    21,   345, 17371,   982,    20,    14,   503,\n",
       "          1961,    48,   982,  8918,    18,    14,  1961,    77,  3332,    17,\n",
       "          9584,    18,  4138,    68,  8120,    17,   895,   969,  9168,  3808,\n",
       "            26,   206,   632,   158,  4138,    68,  8120,    50, 23350,    34,\n",
       "            14, 10771,   895,   969,  9168,  3808,     3,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(token):\n",
    "    with torch.no_grad():\n",
    "        out = model(token)\n",
    "        out = net(out[0].mean(axis=1))\n",
    "      \n",
    "    return out[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence_vec = transform(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sim = {}\n",
    "for num, v in ALBERT_vec.items():\n",
    "    sim[num] = np.dot(input_sentence_vec, v)\n",
    "\n",
    "sorted_sim = sorted(sim.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CN106096670B', 0.42114612),\n",
       " ('US20170206431A1', 0.4207488),\n",
       " ('US10311321B1', 0.4203884),\n",
       " ('US10304009B1', 0.41970453),\n",
       " ('US10430691B1', 0.41670448),\n",
       " ('US10373027B1', 0.41570273),\n",
       " ('WO2018071424A1', 0.41545564),\n",
       " ('US10467501B2', 0.4144406),\n",
       " ('US20110311129A1', 0.4131378),\n",
       " ('US10438082B1', 0.41306487)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_sim[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_abstract = \"We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is far less likely to predict false detections where nothing exists. Finally, YOLO learns very general representations of objects. It outperforms all other detection methods, including DPM and R-CNN, by a wide margin when generalizing from natural images to artwork on both the Picasso Dataset and the People-Art Dataset.\"\n",
    "SSD_abstract = \"We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. Our SSD model is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stage and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, MS COCO, and ILSVRC datasets confirm that SSD has comparable accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. Compared to other single stage methods, SSD has much better accuracy, even with a smaller input image size. For 300×300 input, SSD achieves 72.1% mAP on VOC2007 test at 58 FPS on a Nvidia Titan X and for 500×500 input, SSD achieves 75.1% mAP, outperforming a comparable state of the art Faster R-CNN model. Code is available at this https URL .\"\n",
    "MASK_RCNN_abstract = \"We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without bells and whistles, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code has been made available at: this https URL\"\n",
    "YOLOv3_abstract = \"We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at this https URL\"\n",
    "\n",
    "sentences = {\"YOLO\":YOLO_abstract, \"SSD\":SSD_abstract, \"MASK_RCNN\": MASK_RCNN_abstract, \"YOLOv3\": YOLOv3_abstract}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.52 s, sys: 15.6 ms, total: 4.53 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tmp = {}\n",
    "sorted_sim = {}\n",
    "\n",
    "for title, sentence in sentences.items():\n",
    "    sentence =abstract_preprocess(sentence)\n",
    "    token = torch.tensor(tokenizer.encode(sentence, \n",
    "                         add_special_tokens=True, \n",
    "                         max_length=256, \n",
    "                         pad_to_max_length=True)).unsqueeze(0)\n",
    "    sentence_vec = transform(token)\n",
    "    \n",
    "    for num, v in ALBERT_vec.items():\n",
    "        tmp[num] = np.dot(sentence_vec, v)\n",
    "\n",
    "    sorted_sim[title] = sorted(tmp.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('WO2018071424A1', 0.96971464),\n",
       " ('US20120207346A1', 0.9680863),\n",
       " ('US10198671B1', 0.96720666),\n",
       " ('WO2019148729A1', 0.9668399),\n",
       " ('TWI624793B', 0.9667752),\n",
       " ('US9147255B1', 0.96672106),\n",
       " ('US20190012548A1', 0.9648615),\n",
       " ('US9984325B1', 0.96396375),\n",
       " ('US20180285686A1', 0.9639571),\n",
       " ('US10366430B2', 0.9638148),\n",
       " ('US9858496B2', 0.9638113),\n",
       " ('US20170124415A1', 0.96223944),\n",
       " ('US10387753B1', 0.9617574),\n",
       " ('WO2019220622A1', 0.96174854),\n",
       " ('US10395140B1', 0.96156275),\n",
       " ('US10438082B1', 0.9610427),\n",
       " ('WO2019136479A1', 0.9609129),\n",
       " ('US10410120B1', 0.96059734),\n",
       " ('US10496899B1', 0.9602724),\n",
       " ('US10387754B1', 0.9602562),\n",
       " ('US10380741B2', 0.9600182),\n",
       " ('US20100124361A1', 0.9598441),\n",
       " ('US7890443B2', 0.9598025),\n",
       " ('US20190073553A1', 0.95975596),\n",
       " ('US20190050681A1', 0.95922077),\n",
       " ('US20190130191A1', 0.95887834),\n",
       " ('US20180096457A1', 0.9586959),\n",
       " ('US10255522B2', 0.9585273),\n",
       " ('US10325185B1', 0.95846385),\n",
       " ('US9881234B2', 0.9583591),\n",
       " ('US10373027B1', 0.95814407),\n",
       " ('US10387740B2', 0.95809364),\n",
       " ('US10496895B2', 0.9580158),\n",
       " ('US9965719B2', 0.9579742),\n",
       " ('US20180158189A1', 0.95771855),\n",
       " ('US20180268292A1', 0.9575078),\n",
       " ('US10304009B1', 0.95749944),\n",
       " ('US20170132472A1', 0.9573409),\n",
       " ('CN108520229A', 0.9569057),\n",
       " ('US20170262996A1', 0.95690507),\n",
       " ('US10445611B1', 0.95685),\n",
       " ('US20180341872A1', 0.9568226),\n",
       " ('US10007865B1', 0.9567258),\n",
       " ('US20160104058A1', 0.9566875),\n",
       " ('US20190034734A1', 0.95639247),\n",
       " ('US8010471B2', 0.95607376),\n",
       " ('US10325352B1', 0.9559025),\n",
       " ('CN106599939A', 0.95565444),\n",
       " ('CN110222565A', 0.95555204),\n",
       " ('US10402695B1', 0.95540446),\n",
       " ('CN107562925A', 0.9551657),\n",
       " ('CN106295502B', 0.9550436),\n",
       " ('US20180268234A1', 0.9549959),\n",
       " ('US20180137642A1', 0.9548033),\n",
       " ('US10169679B1', 0.95462453),\n",
       " ('US9165369B1', 0.9545538),\n",
       " ('US20170220876A1', 0.95454276),\n",
       " ('US20170124409A1', 0.95444286),\n",
       " ('US20170011281A1', 0.95438147),\n",
       " ('CN106548182A', 0.9540705),\n",
       " ('CN107908536A', 0.9539799),\n",
       " ('US20110311129A1', 0.9539722),\n",
       " ('US10430691B1', 0.9532721),\n",
       " ('US7634137B2', 0.9532508),\n",
       " ('US10223610B1', 0.95320964),\n",
       " ('US10354362B2', 0.9528567),\n",
       " ('US9946960B1', 0.95273614),\n",
       " ('CN108573228A', 0.9526751),\n",
       " ('US10402692B1', 0.95253116),\n",
       " ('US10311321B1', 0.9523025),\n",
       " ('US10303956B2', 0.9518148),\n",
       " ('US20190065867A1', 0.9516401),\n",
       " ('US20180211403A1', 0.95107466),\n",
       " ('US10255525B1', 0.9507032),\n",
       " ('US10229346B1', 0.9506245),\n",
       " ('US10586336B2', 0.95061636),\n",
       " ('US10467501B2', 0.9506015),\n",
       " ('US10402686B1', 0.9504971),\n",
       " ('CN105740799A', 0.95038104),\n",
       " ('US20190057507A1', 0.95026845),\n",
       " ('WO2019068141A1', 0.95006174),\n",
       " ('CN106096670B', 0.9498402),\n",
       " ('US10095977B1', 0.9497618),\n",
       " ('US20170294124A1', 0.94954395),\n",
       " ('US10423860B1', 0.9495016),\n",
       " ('US10242294B2', 0.94923484),\n",
       " ('US10262237B2', 0.9491146),\n",
       " ('US10373323B1', 0.9490169),\n",
       " ('US20170147905A1', 0.94892067),\n",
       " ('US10346693B1', 0.9487548),\n",
       " ('US9489598B2', 0.9484963),\n",
       " ('US20160358069A1', 0.94807595),\n",
       " ('US20160148079A1', 0.94741505),\n",
       " ('US10043113B1', 0.94734704),\n",
       " ('US20170169315A1', 0.94709396),\n",
       " ('US20190019037A1', 0.9470411),\n",
       " ('US20170206431A1', 0.9454924),\n",
       " ('US9418319B2', 0.94490564),\n",
       " ('US20180107866A1', 0.94473815),\n",
       " ('US10303981B1', 0.94442785),\n",
       " ('US20140270551A1', 0.94439656),\n",
       " ('US20180068198A1', 0.9437693),\n",
       " ('US10579924B1', 0.9435622),\n",
       " ('US10452980B1', 0.9428497),\n",
       " ('US20180165551A1', 0.94253427),\n",
       " ('US9947103B1', 0.94231087),\n",
       " ('US20180336469A1', 0.9419162),\n",
       " ('US10509987B1', 0.9418657),\n",
       " ('US20180260415A1', 0.9411412),\n",
       " ('US20180247180A1', 0.9407803),\n",
       " ('US20190130583A1', 0.9401682),\n",
       " ('US10223614B1', 0.93982404),\n",
       " ('US20180253866A1', 0.9374831),\n",
       " ('US5729471A', 0.93732864),\n",
       " ('US10387752B1', 0.9352362),\n",
       " ('US10002313B2', 0.9345217),\n",
       " ('US20170185871A1', 0.9284811),\n",
       " ('US7715597B2', 0.90818006),\n",
       " ('US20180107926A1', 0.90492344),\n",
       " ('CN108509854A', 0.89440584),\n",
       " ('US20170132496A1', 0.8877715),\n",
       " ('US9202144B2', 0.8134451),\n",
       " ('US8306942B2', 0.7281277),\n",
       " ('US20150086087A1', 0.4669057),\n",
       " ('US20190072977A1', 0.42167273),\n",
       " ('US9158970B2', 0.3733764),\n",
       " ('US10560362B2', 0.337333),\n",
       " ('US20160065931A1', 0.3282444),\n",
       " ('US20190020871A1', 0.25551644),\n",
       " ('CN107784315A', 0.22731724),\n",
       " ('US20180211099A1', 0.2229615),\n",
       " ('US7596247B2', 0.19158341),\n",
       " ('CN1068688C', 0.17537397),\n",
       " ('US20180129869A1', 0.17441913),\n",
       " ('US20160357748A1', 0.15892455),\n",
       " ('US20130121584A1', 0.14391366),\n",
       " ('CN103136309B', 0.14022085),\n",
       " ('CN107330432A', 0.13972178),\n",
       " ('US20160307072A1', 0.12464061),\n",
       " ('RU2640322C2', 0.12294808),\n",
       " ('CN108182394A', 0.12019324),\n",
       " ('CN109063695A', 0.106169865),\n",
       " ('US9020263B2', 0.10616167),\n",
       " ('US20100098295A1', 0.098587826),\n",
       " ('US20160086020A1', 0.09750408),\n",
       " ('US20090116698A1', 0.09592062),\n",
       " ('US10322510B2', 0.09383769),\n",
       " ('US20140341422A1', 0.09011877),\n",
       " ('US20170372174A1', 0.088169724),\n",
       " ('US9563855B2', 0.08474797),\n",
       " ('CN107145833A', 0.08077215),\n",
       " ('US20150036942A1', 0.08038631),\n",
       " ('US20180267997A1', 0.07767171),\n",
       " ('US9892326B2', 0.07585969),\n",
       " ('US20190096125A1', 0.074517764),\n",
       " ('US20180075290A1', 0.06921162),\n",
       " ('US10354144B2', 0.06861736),\n",
       " ('CN106250812B', 0.06310514),\n",
       " ('CN104834747A', 0.06305252),\n",
       " ('US20180285659A1', 0.06171681),\n",
       " ('US8346017B2', 0.06083265),\n",
       " ('US20190045168A1', 0.060011562),\n",
       " ('US6650779B2', 0.05916237),\n",
       " ('US9213919B2', 0.0531186),\n",
       " ('US8100552B2', 0.050315633),\n",
       " ('US20170262695A1', 0.048520207),\n",
       " ('JP2010186216A', 0.04791501),\n",
       " ('US20180107925A1', 0.045593545),\n",
       " ('US20180114055A1', 0.043903608),\n",
       " ('EP3136289A1', 0.04190314),\n",
       " ('US20120313955A1', 0.041705273),\n",
       " ('US9721148B2', 0.041009117),\n",
       " ('US20170039436A1', 0.03970688),\n",
       " ('US5995651A', 0.039698884),\n",
       " ('US20190163193A1', 0.03846485),\n",
       " ('US9400925B2', 0.037900046),\n",
       " ('WO2016145379A1', 0.030965367),\n",
       " ('US20110044537A1', 0.024326004),\n",
       " ('US20170083762A1', 0.023220984),\n",
       " ('US20150278579A1', 0.021576433),\n",
       " ('CN108230292A', 0.021401107),\n",
       " ('US9207760B1', 0.021008465),\n",
       " ('US20160173568A1', 0.019831374),\n",
       " ('US10560696B2', 0.017642964),\n",
       " ('US6819790B2', 0.015278001),\n",
       " ('US20170286809A1', 0.014496442),\n",
       " ('CN107688819A', 0.014241617),\n",
       " ('US20180114390A1', 0.014201225),\n",
       " ('US9361523B1', 0.013270841),\n",
       " ('CN107562805A', 0.011213347),\n",
       " ('US10277950B2', 0.010054601),\n",
       " ('US20130054106A1', 0.0077296747),\n",
       " ('CN106991363A', 0.0076487693),\n",
       " ('US8670592B2', 0.005100266),\n",
       " ('US20190102646A1', 0.0050660064),\n",
       " ('US20160070956A1', 0.0043340162),\n",
       " ('US20170344808A1', 0.0038659228),\n",
       " ('US20140321733A1', 0.00085207145),\n",
       " ('CN108012156A', 0.00071235956),\n",
       " ('US20160321784A1', 0.00014322466),\n",
       " ('CN104680120B', -0.000113327755),\n",
       " ('WO2018208939A1', -0.00086000323),\n",
       " ('US20150127648A1', -0.0014428184),\n",
       " ('CN108009509A', -0.0036895506),\n",
       " ('US9852364B2', -0.004092048),\n",
       " ('US20150235073A1', -0.006597205),\n",
       " ('US20170069159A1', -0.0067297216),\n",
       " ('US20070077987A1', -0.0071833823),\n",
       " ('RU2651147C1', -0.008428568),\n",
       " ('US6820897B2', -0.010957122),\n",
       " ('US7848566B2', -0.011810494),\n",
       " ('US20170046616A1', -0.01355149),\n",
       " ('US20170053375A1', -0.013609313),\n",
       " ('US20150123967A1', -0.015783556),\n",
       " ('US20180232471A1', -0.01848162),\n",
       " ('US20180247405A1', -0.019088713),\n",
       " ('US9122950B2', -0.019716123),\n",
       " ('US9830529B2', -0.020046849),\n",
       " ('CN106650637A', -0.021714505),\n",
       " ('US9665802B2', -0.022192474),\n",
       " ('US6671400B1', -0.023614848),\n",
       " ('CN108197544A', -0.024435034),\n",
       " ('US20180197081A1', -0.0269695),\n",
       " ('JP6268960B2', -0.027144903),\n",
       " ('US20180330238A1', -0.02876271),\n",
       " ('US20130335571A1', -0.029076207),\n",
       " ('CN106358444B', -0.029597279),\n",
       " ('US8611695B1', -0.031366803),\n",
       " ('US20160283864A1', -0.03159235),\n",
       " ('CN106575367B', -0.035031267),\n",
       " ('US8441548B1', -0.035093237),\n",
       " ('CN105138953B', -0.03682375),\n",
       " ('US8977003B1', -0.037899353),\n",
       " ('US20190095777A1', -0.038649667),\n",
       " ('US20190026917A1', -0.03917621),\n",
       " ('US8744172B2', -0.040231213),\n",
       " ('WO2008081143A2', -0.04029271),\n",
       " ('US20150154471A1', -0.041346267),\n",
       " ('US20140149465A1', -0.042956535),\n",
       " ('US20100191391A1', -0.043033477),\n",
       " ('US7346196B2', -0.044293534),\n",
       " ('US20160182874A1', -0.045877956),\n",
       " ('US10430966B2', -0.047118146),\n",
       " ('US20060245653A1', -0.048102338),\n",
       " ('RU173468U1', -0.048621085),\n",
       " ('US10019651B1', -0.050046865),\n",
       " ('US9530192B2', -0.053226106),\n",
       " ('US20080183535A1', -0.054136243),\n",
       " ('CN107273836A', -0.054866724),\n",
       " ('US20100100268A1', -0.05543175),\n",
       " ('JP2013110569A', -0.056450572),\n",
       " ('US5995639A', -0.05801882),\n",
       " ('US8577130B2', -0.05867128),\n",
       " ('US10433112B2', -0.060103733),\n",
       " ('US10572770B2', -0.060426388),\n",
       " ('US20170083788A1', -0.060717974),\n",
       " ('US10275684B2', -0.062830634),\n",
       " ('US9639742B2', -0.06307942),\n",
       " ('KR100695136B1', -0.06656057),\n",
       " ('US7904187B2', -0.06686668),\n",
       " ('US20150269733A1', -0.069473825),\n",
       " ('US9870649B1', -0.07133307),\n",
       " ('US20150178265A1', -0.07151069),\n",
       " ('US20170286774A1', -0.0719656),\n",
       " ('US20190213438A1', -0.074263826),\n",
       " ('CN104732248B', -0.074674085),\n",
       " ('US9373057B1', -0.07504657),\n",
       " ('US8649594B1', -0.07791974),\n",
       " ('US20090202145A1', -0.07795631),\n",
       " ('CN104732483A', -0.07802913),\n",
       " ('US20160358337A1', -0.08087565),\n",
       " ('US20160171285A1', -0.08311828),\n",
       " ('US20140132758A1', -0.08357794),\n",
       " ('US10402628B2', -0.08592172),\n",
       " ('US8214238B1', -0.08741222),\n",
       " ('EP1335783B1', -0.08848515),\n",
       " ('CN107169463B', -0.08893314),\n",
       " ('CN108038540A', -0.08985286),\n",
       " ('US20180129887A1', -0.091103405),\n",
       " ('US20140125806A1', -0.09490565),\n",
       " ('US9471836B1', -0.09558055),\n",
       " ('US20190164290A1', -0.095636),\n",
       " ('US20190188525A1', -0.09815048),\n",
       " ('US20160148080A1', -0.09932007),\n",
       " ('CN105303162A', -0.09941347),\n",
       " ('WO2013114212A2', -0.102534175),\n",
       " ('US10417527B2', -0.10298002),\n",
       " ('US10346717B1', -0.1040677),\n",
       " ('US20190197331A1', -0.104880475),\n",
       " ('US20190073563A1', -0.10609737),\n",
       " ('US20120068920A1', -0.10916618),\n",
       " ('JP2018081402A', -0.10989731),\n",
       " ('US9361510B2', -0.11069524),\n",
       " ('US20150234045A1', -0.11240298),\n",
       " ('US20090196467A1', -0.11284829),\n",
       " ('US20180373963A1', -0.11401123),\n",
       " ('US20150023553A1', -0.11509405),\n",
       " ('US20170120803A1', -0.115274794),\n",
       " ('US20190236411A1', -0.116029486),\n",
       " ('US8494285B2', -0.11620533),\n",
       " ('US8860715B2', -0.11776325),\n",
       " ('US7006881B1', -0.11797873),\n",
       " ('US20180032857A1', -0.118501924),\n",
       " ('US5930392A', -0.11924918),\n",
       " ('CN107665353A', -0.119379416),\n",
       " ('CN107463962A', -0.12044174),\n",
       " ('US7194114B2', -0.12097257),\n",
       " ('US20190129413A1', -0.12178693),\n",
       " ('US20050198661A1', -0.12250021),\n",
       " ('US9785919B2', -0.123179674),\n",
       " ('US20170286752A1', -0.123925954),\n",
       " ('WO2017132846A1', -0.1254278),\n",
       " ('US9443198B1', -0.12546696),\n",
       " ('US20180374341A1', -0.12915662),\n",
       " ('JP5469216B2', -0.12925902),\n",
       " ('US9934440B1', -0.12934944),\n",
       " ('US9984305B2', -0.12959641),\n",
       " ('US10449956B2', -0.13030949),\n",
       " ('US8463025B2', -0.1303901),\n",
       " ('US20120083974A1', -0.1304683),\n",
       " ('JP2010524111A', -0.13091353),\n",
       " ('US20150354976A1', -0.13301705),\n",
       " ('US20160239706A1', -0.1336032),\n",
       " ('US20150317511A1', -0.13661458),\n",
       " ('US10127495B1', -0.13776591),\n",
       " ('US6337692B1', -0.13926776),\n",
       " ('US20190095842A1', -0.13961619),\n",
       " ('US5479576A', -0.13976641),\n",
       " ('US20160132718A1', -0.1400833),\n",
       " ('US20090185723A1', -0.14013346),\n",
       " ('US20160171341A1', -0.14189309),\n",
       " ('US7194134B2', -0.14497928),\n",
       " ('US20070239494A1', -0.14532734),\n",
       " ('US20190172223A1', -0.1466356),\n",
       " ('US20110293189A1', -0.14910208),\n",
       " ('CN105678321A', -0.15013868),\n",
       " ('US10346724B2', -0.15058134),\n",
       " ('US20070047838A1', -0.15351127),\n",
       " ('US20130250050A1', -0.15429084),\n",
       " ('CN106778472A', -0.15710205),\n",
       " ('US20180229737A1', -0.15710805),\n",
       " ('DE102018210632A1', -0.15905647),\n",
       " ('JP3173040B2', -0.15909153),\n",
       " ('US7274822B2', -0.16044673),\n",
       " ('US7219085B2', -0.16126864),\n",
       " ('CN106599878A', -0.16156635),\n",
       " ('US20190050673A1', -0.1631189),\n",
       " ('US9947228B1', -0.1633723),\n",
       " ('US20130179382A1', -0.16353196),\n",
       " ('US7813822B1', -0.16472442),\n",
       " ('CN105760899B', -0.16516888),\n",
       " ('US20100296740A1', -0.16764835),\n",
       " ('US20180321679A1', -0.16899754),\n",
       " ('CN107463892A', -0.16904189),\n",
       " ('US9208404B2', -0.17051443),\n",
       " ('WO2016133767A1', -0.17385544),\n",
       " ('US20160217368A1', -0.17717426),\n",
       " ('US20180012374A1', -0.17748892),\n",
       " ('US10546389B2', -0.17762339),\n",
       " ('US8687893B2', -0.17780298),\n",
       " ('US20120070035A1', -0.17962608),\n",
       " ('US20140161334A1', -0.18074071),\n",
       " ('US20190108640A1', -0.18267268),\n",
       " ('WO2019246250A1', -0.18360339),\n",
       " ('CN102479329A', -0.19067448),\n",
       " ('JP5808371B2', -0.19111802),\n",
       " ('US20180039853A1', -0.19168516),\n",
       " ('JP2011257805A', -0.19340795),\n",
       " ('KR101381439B1', -0.19715588),\n",
       " ('US20160155011A1', -0.20087183),\n",
       " ('GB2549554A', -0.20271656),\n",
       " ('US20180012092A1', -0.20418088),\n",
       " ('US8509538B2', -0.20538017),\n",
       " ('US10262218B2', -0.20585565),\n",
       " ('US20170186176A1', -0.20761856),\n",
       " ('US20120070036A1', -0.20874259),\n",
       " ('US20140270522A1', -0.21035936),\n",
       " ('US20170364750A1', -0.21075618),\n",
       " ('US8396268B2', -0.21242857),\n",
       " ('US20170098124A1', -0.21276815),\n",
       " ('US20090324060A1', -0.21338585),\n",
       " ('US20150242709A1', -0.21379614),\n",
       " ('US8098906B2', -0.2160834),\n",
       " ('US20060252554A1', -0.22294408),\n",
       " ('US10013620B1', -0.22314218),\n",
       " ('US8131065B2', -0.22821201),\n",
       " ('JP2017208004A', -0.23064868),\n",
       " ('JP2014153837A', -0.2318202),\n",
       " ('US20170308770A1', -0.2326797),\n",
       " ('US20130015946A1', -0.23348454),\n",
       " ('CN107220618A', -0.23702084),\n",
       " ('US20190073568A1', -0.23739105),\n",
       " ('US9996890B1', -0.23896934),\n",
       " ('JP2018045309A', -0.24167036),\n",
       " ('US20160283841A1', -0.24192277),\n",
       " ('US20110157355A1', -0.24318148),\n",
       " ('US10572748B2', -0.24383801),\n",
       " ('US20150339811A1', -0.24842587),\n",
       " ('US20140355861A1', -0.2486368),\n",
       " ('US20180253622A1', -0.25015098),\n",
       " ('US20130243246A1', -0.25073904),\n",
       " ('US8543519B2', -0.25631905),\n",
       " ('US7319780B2', -0.2593443),\n",
       " ('US20020186144A1', -0.26001006),\n",
       " ('US10262187B1', -0.26043504),\n",
       " ('US20180342061A1', -0.26064357),\n",
       " ('US10424086B2', -0.26818088),\n",
       " ('US20150063708A1', -0.2738762),\n",
       " ('US20190019050A1', -0.27416763),\n",
       " ('US20150234942A1', -0.27723184),\n",
       " ('US20120230545A1', -0.27901638),\n",
       " ('US7603000B2', -0.2807132),\n",
       " ('US20110249073A1', -0.28230223),\n",
       " ('US7961986B1', -0.28435358),\n",
       " ('US20120140061A1', -0.29479948),\n",
       " ('US20140278390A1', -0.29523277),\n",
       " ('TWI621075B', -0.2983601),\n",
       " ('US20140254923A1', -0.3076675),\n",
       " ('CN104412300B', -0.3082689),\n",
       " ('US20130066592A1', -0.3087383),\n",
       " ('CN104732549A', -0.31531858),\n",
       " ('US20180025235A1', -0.3255514),\n",
       " ('US20180373975A1', -0.34674907),\n",
       " ('US20160171331A1', -0.3468713),\n",
       " ('US9111255B2', -0.36179385),\n",
       " ('CN102210559A', -0.36218107),\n",
       " ('US10169661B2', -0.42139903),\n",
       " ('US20160292589A1', -0.435423),\n",
       " ('WO2019203954A1', -0.45527807),\n",
       " ('JP2018096830A', -0.46334898),\n",
       " ('JP2015064778A', -0.47852024),\n",
       " ('US10382770B2', -0.5100293),\n",
       " ('US20170339417A1', -0.6035695)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_sim[\"SSD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "def dump(fname, obj):\n",
    "  with gzip.open(fname, 'wb') as f:\n",
    "     pickle.dump(obj, f)\n",
    "\n",
    "        \n",
    "dump(\"sentences.pkl.gz\", sentences)\n",
    "dump(\"sorted_sim.pkl.gz\", sorted_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region_Proposal_Networks = \"A Region Proposal Network (RPN) takes an image (of any size) as input and outputs a set of rectangular object proposals, each with an objectness score. We model this process with a fully convolutional network, which we describe in this section. Because our ultimate goal is to share computation with a Fast R-CNN object detection network, we assume that both nets share a common set of convolutional layers. In our experiments, we investigate the Zeiler and Fergus model (ZF), which has 5 shareable convolutional layers and the Simonyan and Zisserman model (VGG-16), which has 13 shareable convolutional layers.\"\n",
    "Anchor = \"At each sliding-window location, we simultaneously predict multiple region proposals, where the number of maximum possible proposals for each location is denoted as k. So the reg layer has 4k outputs encoding the coordinates of k boxes, and the cls layer outputs 2k scores that estimate probability of object or not object for each proposal. The k proposals are parameterized relative to k reference boxes, which we call anchors. An anchor is centered at the sliding window in question, and is associated with a scale and aspect ratio. By default we use 3 scales and 3 aspect ratios, yielding k = 9 anchors at each sliding position. For a convolutional feature map of a size W × H (typically ∼2,400), there are W Hk anchors in total.\"\n",
    "Translation_Invariant = \"An important property of our approach is that it is translation invariant, both in terms of the anchors and the functions that compute proposals relative to the anchors. If one translates an object in an image, the proposal should translate and the same function should be able to predict the proposal in either location. This translation-invariant property is guaranteed by our method. As a comparison, the MultiBox method uses k-means to generate 800 anchors, which are not translation invariant. So MultiBox does not guarantee that the same proposal is generated if an object is translated.\"\n",
    "Multi_Scale_Anchors = \"Our design of anchors presents a novel scheme for addressing multiple scales (and aspect ratios). As shown in Figure, there have been two popular ways for multi-scale predictions. The first way is based on image/feature pyramids, e.g., in DPM and CNNbased methods. The images are resized at multiple scales, and feature maps (HOG or deep convolutional features) are computed for each scale. This way is often useful but is time-consuming. The second way is to use sliding windows of multiple scales (and/or aspect ratios) on the feature maps. For example, in DPM, models of different aspect ratios are trained separately using different filter sizes (such as 5×7 and 7×5). If this way is used to address multiple scales, it can be thought of as a pyramid of filters. The second way is usually adopted jointly with the first way.\"\n",
    "\n",
    "sentences = {\"Region_Proposal_Networks\":Region_Proposal_Networks,\n",
    "             \"Anchor\":Anchor, \"Translation_Invariant\": Translation_Invariant,\n",
    "             \"Multi_Scale_Anchors\": Multi_Scale_Anchors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AlbertTokenizer\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.53 s, sys: 46.9 ms, total: 4.58 s\n",
      "Wall time: 2.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tmp = {}\n",
    "sorted_sim = {}\n",
    "\n",
    "for title, sentence in sentences.items():\n",
    "    sentence =abstract_preprocess(sentence)\n",
    "    token = torch.tensor(tokenizer.encode(sentence, \n",
    "                         add_special_tokens=True, \n",
    "                         max_length=256, \n",
    "                         pad_to_max_length=True)).unsqueeze(0)\n",
    "    sentence_vec = transform(token)\n",
    "    \n",
    "    for num, v in ALBERT_vec.items():\n",
    "        tmp[num] = np.dot(sentence_vec, v)\n",
    "\n",
    "    sorted_sim[title] = sorted(tmp.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "def dump(fname, obj):\n",
    "  with gzip.open(fname, 'wb') as f:\n",
    "     pickle.dump(obj, f)\n",
    "\n",
    "        \n",
    "dump(\"sentences_body.pkl.gz\", sentences)\n",
    "dump(\"sorted_sim_body.pkl.gz\", sorted_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, sentence in sentences.items():\n",
    "    sentence =abstract_preprocess(sentence)\n",
    "    token = torch.tensor(tokenizer.encode(sentence, \n",
    "                         add_special_tokens=True, \n",
    "                         max_length=256, \n",
    "                         pad_to_max_length=True)).unsqueeze(0)\n",
    "    sentence_vec = transform(token)\n",
    "    ALBERT_vec[title] = sentence_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "PCA_vec = PCA(n_components=2).fit_transform(list(ALBERT_vec.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(437, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_citation_count = []\n",
    "for num in df.index:\n",
    "    forward_citation_count.append(len(references[num][\"ForwardReferences\"] ))\n",
    "\n",
    "forward_citation_count += [10]*4\n",
    "len(forward_citation_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>assignee</th>\n",
       "      <th>PCA_1</th>\n",
       "      <th>PCA_2</th>\n",
       "      <th>forward_citation_count</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US9858496B2</td>\n",
       "      <td>Microsoft Technology Licensing LLC</td>\n",
       "      <td>-0.412363</td>\n",
       "      <td>-0.672956</td>\n",
       "      <td>35</td>\n",
       "      <td>13.441912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US20180107866A1</td>\n",
       "      <td>Snap Inc</td>\n",
       "      <td>-0.448296</td>\n",
       "      <td>-0.659061</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN108520229A</td>\n",
       "      <td>北京旷视科技有限公司</td>\n",
       "      <td>-0.415449</td>\n",
       "      <td>-0.668391</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN108573228A</td>\n",
       "      <td>杭州华雁云态信息技术有限公司</td>\n",
       "      <td>-0.462654</td>\n",
       "      <td>-0.652285</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US10242294B2</td>\n",
       "      <td>Intel Corp</td>\n",
       "      <td>-0.475543</td>\n",
       "      <td>-0.648362</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                            assignee     PCA_1     PCA_2  \\\n",
       "0      US9858496B2  Microsoft Technology Licensing LLC -0.412363 -0.672956   \n",
       "1  US20180107866A1                            Snap Inc -0.448296 -0.659061   \n",
       "2     CN108520229A                          北京旷视科技有限公司 -0.415449 -0.668391   \n",
       "3     CN108573228A                      杭州华雁云态信息技术有限公司 -0.462654 -0.652285   \n",
       "4     US10242294B2                          Intel Corp -0.475543 -0.648362   \n",
       "\n",
       "   forward_citation_count       size  \n",
       "0                      35  13.441912  \n",
       "1                       0   5.000000  \n",
       "2                       0   5.000000  \n",
       "3                       0   5.000000  \n",
       "4                       0   5.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reduced_vec = pd.DataFrame(dict(id = list(ALBERT_vec.keys()), assignee = list(df[\"assignee\"]) + list(sentences.keys()),\n",
    "                            PCA_1 = PCA_vec[:,0], PCA_2 = PCA_vec[:,1], \n",
    "                            forward_citation_count = forward_citation_count,\n",
    "                            size = [min(5 + (elm)**0.6, 30) for elm in forward_citation_count],\n",
    "                           ))\n",
    "reduced_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>assignee</th>\n",
       "      <th>PCA_1</th>\n",
       "      <th>PCA_2</th>\n",
       "      <th>forward_citation_count</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>US8441548B1</td>\n",
       "      <td>Google LLC</td>\n",
       "      <td>0.715043</td>\n",
       "      <td>-0.015068</td>\n",
       "      <td>16</td>\n",
       "      <td>10.278032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>Region_Proposal_Networks</td>\n",
       "      <td>Region_Proposal_Networks</td>\n",
       "      <td>-0.345556</td>\n",
       "      <td>-0.259991</td>\n",
       "      <td>10</td>\n",
       "      <td>8.981072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>Anchor</td>\n",
       "      <td>Anchor</td>\n",
       "      <td>-0.217291</td>\n",
       "      <td>-0.115741</td>\n",
       "      <td>10</td>\n",
       "      <td>8.981072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Translation_Invariant</td>\n",
       "      <td>Translation_Invariant</td>\n",
       "      <td>-0.075213</td>\n",
       "      <td>-0.218505</td>\n",
       "      <td>10</td>\n",
       "      <td>8.981072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>Multi_Scale_Anchors</td>\n",
       "      <td>Multi_Scale_Anchors</td>\n",
       "      <td>-0.219259</td>\n",
       "      <td>-0.202031</td>\n",
       "      <td>10</td>\n",
       "      <td>8.981072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id                  assignee     PCA_1     PCA_2  \\\n",
       "432               US8441548B1                Google LLC  0.715043 -0.015068   \n",
       "433  Region_Proposal_Networks  Region_Proposal_Networks -0.345556 -0.259991   \n",
       "434                    Anchor                    Anchor -0.217291 -0.115741   \n",
       "435     Translation_Invariant     Translation_Invariant -0.075213 -0.218505   \n",
       "436       Multi_Scale_Anchors       Multi_Scale_Anchors -0.219259 -0.202031   \n",
       "\n",
       "     forward_citation_count       size  \n",
       "432                      16  10.278032  \n",
       "433                      10   8.981072  \n",
       "434                      10   8.981072  \n",
       "435                      10   8.981072  \n",
       "436                      10   8.981072  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_vec.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "def dump(fname, obj):\n",
    "  with gzip.open(fname, 'wb') as f:\n",
    "     pickle.dump(obj, f)\n",
    "\n",
    "        \n",
    "dump(\"body_reduced_vec.pkl.gz\", reduced_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
